{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6670c91-1ffb-4994-9965-5e7ff0ba57b0",
   "metadata": {},
   "source": [
    "## **2 Overfitting (8 points)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83f990b2-6cac-4f47-9f21-d7923eb5ccc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T06:08:19.339233Z",
     "iopub.status.busy": "2025-09-04T06:08:19.339233Z",
     "iopub.status.idle": "2025-09-04T06:08:22.860213Z",
     "shell.execute_reply": "2025-09-04T06:08:22.858203Z",
     "shell.execute_reply.started": "2025-09-04T06:08:19.339233Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.polynomial.legendre import legvander\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99706e0d-17f9-47e4-8aac-d4a8201bfb60",
   "metadata": {},
   "source": [
    "### (1) Generación de variables y utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f4ca8f8-b11f-47b0-a12b-3f66fb3d578a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T06:08:24.102207Z",
     "iopub.status.busy": "2025-09-04T06:08:24.101207Z",
     "iopub.status.idle": "2025-09-04T06:08:24.108137Z",
     "shell.execute_reply": "2025-09-04T06:08:24.108137Z",
     "shell.execute_reply.started": "2025-09-04T06:08:24.102207Z"
    }
   },
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(2025)\n",
    "n = 1000\n",
    "X = rng.uniform(-1, 1, size=n).astype(np.float32)\n",
    "eps = rng.standard_normal(n).astype(np.float32)\n",
    "Y = (X + eps).astype(np.float32)  # intercepto = 0\n",
    "\n",
    "# grados a probar (número de features)\n",
    "p_list = [1, 2, 5, 10, 20, 50, 100, 200, 500, 1000]\n",
    "\n",
    "\n",
    "\n",
    "def make_leg_features(x, p):\n",
    "    \"\"\"\n",
    "    Devuelve [P1(x), P2(x), ..., Pp(x)], polinomios de Legendre (sin P0).\n",
    "    Mucho más estable que potencias x**k.\n",
    "    \"\"\"\n",
    "    V = legvander(x.astype(np.float64), p)  # columnas P0..Pp\n",
    "    return V[:, 1:].astype(np.float32)      # quitar P0 (intercepto)\n",
    "\n",
    "def adj_r2(r2, n_obs, p):\n",
    "    df = n_obs - p - 1\n",
    "    if df <= 0:\n",
    "        return np.nan\n",
    "    return 1.0 - (1.0 - r2) * (n_obs - 1) / df\n",
    "\n",
    "def fit_no_intercept(Xm, y):\n",
    "    \"\"\"\n",
    "    OLS sin intercepto con lstsq (SVD) y rcond explícito para estabilidad.\n",
    "    Evita problemas de inversión con matrices mal condicionadas.\n",
    "    \"\"\"\n",
    "    beta, *_ = np.linalg.lstsq(Xm, y, rcond=1e-7)\n",
    "    return Xm @ beta\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616faee2-d986-4c7b-bc6d-891e36a3911c",
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-04T06:08:33.842Z",
     "iopub.execute_input": "2025-09-04T06:08:28.436704Z",
     "iopub.status.busy": "2025-09-04T06:08:28.435705Z"
    }
   },
   "outputs": [],
   "source": [
    "rows = []\n",
    "for p in p_list:\n",
    "    Xp = make_leg_features(X, p)\n",
    "\n",
    "    # R2 en toda la muestra\n",
    "    yhat_full = fit_no_intercept(Xp, Y)\n",
    "    r2_full = r2_score(Y, yhat_full)\n",
    "    ar2_full = adj_r2(r2_full, n, p)\n",
    "\n",
    "    # R2 out-of-sample (75/25)\n",
    "    Xtr, Xte, ytr, yte = train_test_split(Xp, Y, test_size=0.25, random_state=2025)\n",
    "    yhat_tr = fit_no_intercept(Xtr, ytr)             # entrena en train\n",
    "    # obtener beta explícito para predecir en test\n",
    "    beta_tr, *_ = np.linalg.lstsq(Xtr, ytr, rcond=1e-7)\n",
    "    yhat_te = Xte @ beta_tr\n",
    "    r2_oos = r2_score(yte, yhat_te)\n",
    "\n",
    "    rows.append({\n",
    "        \"p_features\": p,\n",
    "        \"R2_full\": float(r2_full),\n",
    "        \"Adj_R2_full\": float(ar2_full) if np.isfinite(ar2_full) else np.nan,\n",
    "        \"R2_out_of_sample\": float(r2_oos)\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966fcb5d-9656-4d13-bb35-3f88a6cdcde0",
   "metadata": {},
   "source": [
    "### (5) Gráficos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f56705-1478-4a6c-8639-dccf840075c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf57c884-f493-4032-bce8-0fd12c6b682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# (1) Generación de variables y utilidades\n",
    "rng = np.random.default_rng(3324)\n",
    "n = 1000\n",
    "sigma = 1.0\n",
    "X = rng.standard_normal(n)\n",
    "eps = sigma * rng.standard_normal(n)\n",
    "Y = X + eps\n",
    "\n",
    "p_list = [1, 2, 5, 10, 20, 50, 100, 200, 500, 1000]\n",
    "\n",
    "def datasplitting(df: pd.DataFrame, proportion: float, seed: int = 2025):\n",
    "    rng_local = np.random.default_rng(seed)\n",
    "    idx = np.arange(len(df))\n",
    "    k = int(proportion * len(df))\n",
    "    tr_idx = np.sort(rng_local.choice(idx, size=k, replace=False))\n",
    "    te_mask = np.ones(len(df), dtype=bool)\n",
    "    te_mask[tr_idx] = False\n",
    "    return df.iloc[tr_idx].copy(), df.iloc[te_mask].copy()\n",
    "\n",
    "def r2_in_sample(y, yhat):\n",
    "    y = np.asarray(y); yhat = np.asarray(yhat)\n",
    "    return 1.0 - np.mean((y - yhat)**2) / np.var(y, ddof=0)\n",
    "\n",
    "def r2_adj(y, yhat, p):\n",
    "    y = np.asarray(y); yhat = np.asarray(yhat)\n",
    "    n = y.size\n",
    "    if p >= n: \n",
    "        return np.nan\n",
    "    return 1.0 - ((n/(n - p)) * np.mean((y - yhat)**2)) / np.var(y, ddof=0)\n",
    "\n",
    "def r2_oos(ytest, yhat_test):\n",
    "    ytest = np.asarray(ytest); yhat_test = np.asarray(yhat_test)\n",
    "    return 1.0 - np.mean((ytest - yhat_test)**2) / np.var(ytest, ddof=0)\n",
    "\n",
    "def make_poly_df(x: np.ndarray, y: np.ndarray, p: int) -> pd.DataFrame:\n",
    "    df = pd.DataFrame({\"y\": y})\n",
    "    for k in range(1, p+1):\n",
    "        df[f\"x{k}\"] = x**k\n",
    "    return df\n",
    "\n",
    "# (3) Contenedores\n",
    "R2_full, R2_adj, R2_oos = [], [], []\n",
    "\n",
    "# (4) Estimación con regresión lineal sin intercepto y split 75/25\n",
    "for p in p_list:\n",
    "    df = make_poly_df(X, Y, p)\n",
    "    covs = [f\"x{k}\" for k in range(1, p+1)]\n",
    "    Xfull = df[covs].to_numpy()\n",
    "    yfull = df[\"y\"].to_numpy()\n",
    "\n",
    "    # full sample\n",
    "    m_full = LinearRegression(fit_intercept=False).fit(Xfull, yfull)\n",
    "    yhat_full = m_full.predict(Xfull)\n",
    "    R2_full.append(r2_in_sample(yfull, yhat_full))\n",
    "    R2_adj.append(r2_adj(yfull, yhat_full, p))\n",
    "\n",
    "    # train/test split 75/25\n",
    "    train, test = datasplitting(df, 0.75, seed=2025)\n",
    "    Xtr, ytr = train[covs].to_numpy(), train[\"y\"].to_numpy()\n",
    "    Xte, yte = test[covs].to_numpy(), test[\"y\"].to_numpy()\n",
    "\n",
    "    m_tr = LinearRegression(fit_intercept=False).fit(Xtr, ytr)\n",
    "    yhat_te = m_tr.predict(Xte)\n",
    "    R2_oos.append(r2_oos(yte, yhat_te))\n",
    "\n",
    "# (5) Gráficos\n",
    "plt.figure()\n",
    "plt.plot(p_list, R2_full, marker=\"o\")\n",
    "plt.xscale(\"log\")\n",
    "plt.ylim(-0.5, 1.0)\n",
    "plt.xlabel(\"Número de features (log)\")\n",
    "plt.ylabel(\"R²\")\n",
    "plt.title(\"R² en muestra completa vs complejidad\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(p_list, R2_adj, marker=\"o\")\n",
    "plt.xscale(\"log\")\n",
    "plt.ylim(-0.5, 1.0)\n",
    "plt.xlabel(\"Número de features (log)\")\n",
    "plt.ylabel(\"R² ajustado\")\n",
    "plt.title(\"R² ajustado vs complejidad\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(p_list, R2_oos, marker=\"o\")\n",
    "plt.xscale(\"log\")\n",
    "plt.ylim(-1.0, 1.0)\n",
    "plt.xlabel(\"Número de features (log)\")\n",
    "plt.ylabel(\"R² out-of-sample\")\n",
    "plt.title(\"R² out-of-sample (split 75/25) vs complejidad\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f251ad-dccf-415b-b93d-9051c1e651a8",
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-04T06:11:51.857Z",
     "iopub.execute_input": "2025-09-04T06:11:42.025022Z",
     "iopub.status.busy": "2025-09-04T06:11:42.024023Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ejercicio estable SIN tocar hilos ni librerías raras.\n",
    "# Idea: usar base de Legendre y OLS vía SVD (np.linalg.lstsq).\n",
    "# Para p >= n-1 no hay grados de libertad: reportamos NaN y seguimos.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.polynomial.legendre import legvander\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- DGP ----------\n",
    "rng = np.random.default_rng(2025)\n",
    "n = 1000\n",
    "X = rng.uniform(-1, 1, size=n).astype(np.float64)\n",
    "Y = (X + rng.standard_normal(n)).astype(np.float64)  # intercepto = 0\n",
    "\n",
    "p_list = [1, 2, 5, 10, 20, 50, 100, 200, 500, 1000]\n",
    "\n",
    "# ---------- utilidades ----------\n",
    "def make_leg_features(x, p):\n",
    "    # Matriz de Legendre P0..Pp; quitamos P0 (intercepto)\n",
    "    V = legvander(x, p)[:, 1:]\n",
    "    # normalizamos cada columna para evitar escalas extremas\n",
    "    norms = np.linalg.norm(V, axis=0, keepdims=True)\n",
    "    norms[norms == 0.0] = 1.0\n",
    "    return V / norms\n",
    "\n",
    "def adj_r2(r2, n_obs, p):\n",
    "    df = n_obs - p - 1\n",
    "    return np.nan if df <= 0 else 1.0 - (1.0 - r2) * (n_obs - 1) / df\n",
    "\n",
    "def ols_no_intercept(Xm, y):\n",
    "    # OLS estable por SVD; evita invertir X'X\n",
    "    beta, *_ = np.linalg.lstsq(Xm, y, rcond=None)\n",
    "    return Xm @ beta, beta\n",
    "\n",
    "# ---------- loop ----------\n",
    "rows = []\n",
    "for p in p_list:\n",
    "    if p >= n - 1:\n",
    "        rows.append({\"p_features\": p, \"R2_full\": np.nan, \"Adj_R2_full\": np.nan, \"R2_out_of_sample\": np.nan})\n",
    "        continue\n",
    "\n",
    "    Xp = make_leg_features(X, p)\n",
    "\n",
    "    # full sample\n",
    "    yhat_full, _ = ols_no_intercept(Xp, Y)\n",
    "    r2_full = r2_score(Y, yhat_full)\n",
    "    ar2_full = adj_r2(r2_full, n, p)\n",
    "\n",
    "    # split 75/25\n",
    "    Xtr, Xte, ytr, yte = train_test_split(Xp, Y, test_size=0.25, random_state=2025)\n",
    "    _, beta_tr = ols_no_intercept(Xtr, ytr)\n",
    "    r2_oos = r2_score(yte, Xte @ beta_tr)\n",
    "\n",
    "    rows.append({\"p_features\": p, \"R2_full\": r2_full, \"Adj_R2_full\": ar2_full, \"R2_out_of_sample\": r2_oos})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(df)\n",
    "\n",
    "# ---------- gráficos ----------\n",
    "def plot_col(col, title, ylabel):\n",
    "    plt.figure()\n",
    "    plt.plot(df[\"p_features\"], df[col], marker=\"o\")\n",
    "    plt.xscale(\"log\")\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.xlabel(\"Número de características (p)\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.grid(True, which=\"both\")\n",
    "    plt.show()\n",
    "\n",
    "plot_col(\"R2_full\", \"R² vs p (muestra completa)\", \"R² (full)\")\n",
    "plot_col(\"Adj_R2_full\", \"R² ajustado vs p\", \"R² ajustado\")\n",
    "plot_col(\"R2_out_of_sample\", \"R² out-of-sample vs p\", \"R² OOS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482d2743-6005-458c-bd1f-f297cac0c3f5",
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-04T06:15:50.210Z",
     "iopub.execute_input": "2025-09-04T06:15:43.083057Z",
     "iopub.status.busy": "2025-09-04T06:15:43.083057Z"
    }
   },
   "outputs": [],
   "source": [
    "# Estable: calcula R² hasta p<=300 y salta 500/1000\n",
    "import numpy as np, pandas as pd\n",
    "from numpy.polynomial.legendre import legvander\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- DGP ---\n",
    "rng = np.random.default_rng(2025)\n",
    "n = 1000\n",
    "X = rng.uniform(-1, 1, n).astype(np.float64)\n",
    "Y = (X + rng.standard_normal(n)).astype(np.float64)   # intercepto = 0\n",
    "\n",
    "p_targets = [1,2,5,10,20]\n",
    "p_safe_max = 300                                     # evita cuelgues\n",
    "\n",
    "def make_leg(X, p):\n",
    "    V = legvander(X, p)[:,1:]                        # P1..Pp\n",
    "    # normaliza columnas\n",
    "    s = np.linalg.norm(V, axis=0, keepdims=True); s[s==0]=1\n",
    "    return V/s\n",
    "\n",
    "def adj_r2(r2, n, p):\n",
    "    df = n - p - 1\n",
    "    return np.nan if df<=0 else 1 - (1-r2)*(n-1)/df\n",
    "\n",
    "def ols_no_intercept(Xm, y):\n",
    "    beta, *_ = np.linalg.lstsq(Xm, y, rcond=None)    # SVD estable\n",
    "    return Xm@beta, beta\n",
    "\n",
    "rows=[]\n",
    "for p in p_targets:\n",
    "    if p>p_safe_max or p>=n-1:\n",
    "        # evitar cómputos que matan el kernel\n",
    "        rows.append({\"p_features\": p, \"R2_full\": np.nan,\n",
    "                     \"Adj_R2_full\": np.nan, \"R2_out_of_sample\": np.nan})\n",
    "        continue\n",
    "\n",
    "    Xp = make_leg(X, p)\n",
    "\n",
    "    # full sample\n",
    "    yhat, _ = ols_no_intercept(Xp, Y)\n",
    "    r2f = r2_score(Y, yhat)\n",
    "    ar2 = adj_r2(r2f, n, p)\n",
    "\n",
    "    # 75/25\n",
    "    Xtr,Xte,ytr,yte = train_test_split(Xp, Y, test_size=0.25, random_state=2025)\n",
    "    _, btr = ols_no_intercept(Xtr, ytr)\n",
    "    r2o = r2_score(yte, Xte@btr)\n",
    "\n",
    "    rows.append({\"p_features\": p, \"R2_full\": r2f, \"Adj_R2_full\": ar2, \"R2_out_of_sample\": r2o})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(df)\n",
    "\n",
    "# gráficos\n",
    "def plot_col(col,tit,ylabel):\n",
    "    plt.figure(); plt.plot(df[\"p_features\"], df[col], marker=\"o\")\n",
    "    plt.xscale(\"log\"); plt.ylim(-1,1); plt.xlabel(\"Número de características (p)\")\n",
    "    plt.ylabel(ylabel); plt.title(tit); plt.grid(True, which=\"both\"); plt.show()\n",
    "\n",
    "plot_col(\"R2_full\",\"R² vs p (muestra completa)\",\"R² (full)\")\n",
    "plot_col(\"Adj_R2_full\",\"R² ajustado vs p\",\"R² ajustado\")\n",
    "plot_col(\"R2_out_of_sample\",\"R² out-of-sample vs p\",\"R² OOS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21d76d0b-66a8-49e2-9e1c-b4712750f060",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-04T06:17:34.856653Z",
     "iopub.status.busy": "2025-09-04T06:17:34.855656Z",
     "iopub.status.idle": "2025-09-04T06:17:34.870273Z",
     "shell.execute_reply": "2025-09-04T06:17:34.866713Z",
     "shell.execute_reply.started": "2025-09-04T06:17:34.855656Z"
    }
   },
   "outputs": [],
   "source": [
    "# Celda 0: obligatorio antes de cualquier import\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2da9e37-566b-4c79-8d05-2b127ecbf788",
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-04T06:17:44.237Z",
     "iopub.execute_input": "2025-09-04T06:17:37.136448Z",
     "iopub.status.busy": "2025-09-04T06:17:37.136448Z"
    }
   },
   "outputs": [],
   "source": [
    "# Celda 1: solución estable, sin regularización\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rng = np.random.default_rng(2025)\n",
    "n = 1000\n",
    "X = rng.uniform(-1, 1, size=n).astype(np.float64)\n",
    "Y = (X + rng.standard_normal(n)).astype(np.float64)  # intercepto = 0\n",
    "\n",
    "p_list = [1, 2, 5, 10, 20, 50, 100, 200]\n",
    "\n",
    "def make_poly_features(x, p):\n",
    "    # polinomios de Legendre P1..Pp; más estables que x**k\n",
    "    from numpy.polynomial.legendre import legvander\n",
    "    V = legvander(x, p)[:, 1:]\n",
    "    # normalizar columnas para mejorar condición\n",
    "    s = np.linalg.norm(V, axis=0, keepdims=True); s[s==0]=1.0\n",
    "    return V / s\n",
    "\n",
    "def adj_r2(r2, n_obs, p):\n",
    "    df = n_obs - p - 1\n",
    "    return np.nan if df <= 0 else 1 - (1 - r2) * (n_obs - 1) / df\n",
    "\n",
    "def ols_no_intercept(Xm, y):\n",
    "    # OLS por SVD (estable). Evita invertir X'X.\n",
    "    beta, *_ = np.linalg.lstsq(Xm, y, rcond=1e-7)\n",
    "    return Xm @ beta, beta\n",
    "\n",
    "rows = []\n",
    "for p in p_list:\n",
    "    if p >= n - 1:\n",
    "        rows.append({\"p_features\": p, \"R2_full\": np.nan, \"Adj_R2_full\": np.nan, \"R2_out_of_sample\": np.nan})\n",
    "        continue\n",
    "\n",
    "    Xp = make_poly_features(X, p)\n",
    "\n",
    "    # full sample\n",
    "    yhat_full, _ = ols_no_intercept(Xp, Y)\n",
    "    r2_full = r2_score(Y, yhat_full)\n",
    "    ar2_full = adj_r2(r2_full, n, p)\n",
    "\n",
    "    # 75/25\n",
    "    Xtr, Xte, ytr, yte = train_test_split(Xp, Y, test_size=0.25, random_state=2025)\n",
    "    _, beta_tr = ols_no_intercept(Xtr, ytr)\n",
    "    r2_oos = r2_score(yte, Xte @ beta_tr)\n",
    "\n",
    "    rows.append({\"p_features\": p, \"R2_full\": r2_full, \"Adj_R2_full\": ar2_full, \"R2_out_of_sample\": r2_oos})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(df)\n",
    "\n",
    "# gráficos\n",
    "for col, title, ylabel in [\n",
    "    (\"R2_full\", \"R² vs p (muestra completa)\", \"R² (full)\"),\n",
    "    (\"Adj_R2_full\", \"R² ajustado vs p\", \"R² ajustado\"),\n",
    "    (\"R2_out_of_sample\", \"R² out-of-sample vs p\", \"R² OOS\"),\n",
    "]:\n",
    "    plt.figure()\n",
    "    plt.plot(df[\"p_features\"], df[col], marker=\"o\")\n",
    "    plt.xscale(\"log\"); plt.ylim(-1, 1)\n",
    "    plt.xlabel(\"Número de características (p)\"); plt.ylabel(ylabel)\n",
    "    plt.title(title); plt.grid(True, which=\"both\"); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f235082-a1dc-4532-84ca-602abeadde5a",
   "metadata": {
    "execution": {
     "execution_failed": "2025-09-04T06:22:08.362Z",
     "iopub.execute_input": "2025-09-04T06:22:01.202086Z",
     "iopub.status.busy": "2025-09-04T06:22:01.202086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   p_features   R2_full  Adj_R2_full  R2_out_of_sample\n",
      "0           1  0.129855     0.021087          0.042403\n"
     ]
    }
   ],
   "source": [
    "# Ejercicio estable sin invertir matrices ni usar SVD: OLS por descenso estocástico (SGD)\n",
    "# Cumple: p ∈ {1,2,5,10,20,50,100,200,500,1000}, R2, R2 ajustado, R2 out-of-sample y 3 gráficos.\n",
    "# Evita cuelgues porque no usa lstsq/inversión ni descomposiciones.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- DGP ----------\n",
    "rng = np.random.default_rng(2025)\n",
    "n = 10\n",
    "X = rng.uniform(-1, 1, size=n).astype(np.float64)\n",
    "Y = (X + rng.standard_normal(n)).astype(np.float64)  # intercepto = 0\n",
    "\n",
    "p_list = [1]\n",
    "\n",
    "# ---------- utils ----------\n",
    "def make_poly_features(x, p):\n",
    "    # monomios x, x^2, ..., x^p (con escalado posterior para estabilidad)\n",
    "    cols = [x]\n",
    "    cur = x.copy()\n",
    "    for _ in range(2, p + 1):\n",
    "        cur = cur * x\n",
    "        cols.append(cur)\n",
    "    return np.column_stack(cols)\n",
    "\n",
    "def adj_r2(r2, n_obs, p):\n",
    "    df = n_obs - p - 1\n",
    "    return np.nan if df <= 0 else 1.0 - (1.0 - r2) * (n_obs - 1) / df\n",
    "\n",
    "def fit_predict_sgd(Xm, y):\n",
    "    \"\"\"\n",
    "    OLS sin intercepto aproximado con SGD sin penalización.\n",
    "    Estable y rápido; evita llamadas a LAPACK/BLAS de alto costo.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "    Xs = scaler.fit_transform(Xm)\n",
    "\n",
    "    sgd = SGDRegressor(\n",
    "        loss=\"squared_error\",\n",
    "        penalty=None,          # sin regularización (OLS)\n",
    "        fit_intercept=False,   # intercepto = 0 como pide el enunciado\n",
    "        learning_rate=\"invscaling\",\n",
    "        eta0=0.05, power_t=0.25,\n",
    "        max_iter=4000, tol=1e-6, random_state=2025,\n",
    "        average=True\n",
    "    )\n",
    "    sgd.fit(Xs, y)\n",
    "    yhat = sgd.predict(Xs)\n",
    "    return yhat, (sgd, scaler)\n",
    "\n",
    "def predict_with(model_scaler, Xnew):\n",
    "    sgd, scaler = model_scaler\n",
    "    Xs = scaler.transform(Xnew)\n",
    "    return sgd.predict(Xs)\n",
    "\n",
    "# ---------- loop ----------\n",
    "rows = []\n",
    "for p in p_list:\n",
    "    Xp = make_poly_features(X, p)\n",
    "\n",
    "    # full sample\n",
    "    yhat_full, ms = fit_predict_sgd(Xp, Y)\n",
    "    r2_full = r2_score(Y, yhat_full)\n",
    "    ar2_full = adj_r2(r2_full, n, p)\n",
    "\n",
    "    # 75/25\n",
    "    Xtr, Xte, ytr, yte = train_test_split(Xp, Y, test_size=0.25, random_state=2025)\n",
    "    yhat_tr, ms_tr = fit_predict_sgd(Xtr, ytr)\n",
    "    yhat_te = predict_with(ms_tr, Xte)\n",
    "    r2_oos = r2_score(yte, yhat_te)\n",
    "\n",
    "    rows.append({\"p_features\": p, \"R2_full\": r2_full, \"Adj_R2_full\": ar2_full, \"R2_out_of_sample\": r2_oos})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "print(df)\n",
    "\n",
    "# ---------- gráficos ----------\n",
    "def plot_col(col, title, ylabel):\n",
    "    plt.figure()\n",
    "    plt.plot(df[\"p_features\"], df[col], marker=\"o\")\n",
    "    plt.xscale(\"log\")\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.xlabel(\"Número de características (p)\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(title)\n",
    "    plt.grid(True, which=\"both\")\n",
    "    plt.show()\n",
    "\n",
    "plot_col(\"R2_full\", \"R² vs p (muestra completa)\", \"R² (full)\")\n",
    "plot_col(\"Adj_R2_full\", \"R² ajustado vs p\", \"R² ajustado\")\n",
    "plot_col(\"R2_out_of_sample\", \"R² out-of-sample vs p\", \"R² OOS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2a91ae-4d27-4deb-8dd1-186d16e953bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (overfit)",
   "language": "python",
   "name": "overfit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
