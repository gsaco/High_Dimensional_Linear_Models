{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting Analysis - Python Implementation\n",
    "\n",
    "**Following the exact specifications from the class example**\n",
    "\n",
    "This notebook demonstrates overfitting in high-dimensional linear models using:\n",
    "- Data generating process: f_X = exp(4 * X) - 1\n",
    "- 1000 observations with up to 999 features\n",
    "- Exact R-squared and Adjusted R-squared calculations as specified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries\n",
    "\n",
    "Using the exact libraries as specified:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation - Following Class Example\n",
    "\n",
    "Creating W and e exactly as shown in the class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create W exactly as in the class\n",
    "W = np.random.uniform(0, 1, 1000)\n",
    "W.sort()\n",
    "W = W.reshape(-1, 1)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create e exactly as in the class\n",
    "e = np.random.normal(0,1,1000)\n",
    "e = e.reshape(-1,1)\n",
    "print(e)\n",
    "e.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generating Process\n",
    "\n",
    "Using the specified function: **f_X = exp(4 * X) - 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the data generating process\n",
    "f_X = np.exp(4 * W) - 1\n",
    "y = f_X + e\n",
    "\n",
    "print(\"Data generation complete:\")\n",
    "print(f\"W shape: {W.shape}\")\n",
    "print(f\"f_X range: [{f_X.min():.4f}, {f_X.max():.4f}]\")\n",
    "print(f\"y range: [{y.min():.4f}, {y.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "\n",
    "Split into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data using train_test_split\n",
    "W_train, W_test, y_train, y_test = train_test_split(W, y, test_size=0.25, random_state=42)\n",
    "\n",
    "print(f\"Training set: {len(W_train)} observations\")\n",
    "print(f\"Test set: {len(W_test)} observations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function for Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_polynomial_features(X, degree):\n",
    "    \"\"\"\n",
    "    Create polynomial features: X, X^2, X^3, ..., X^degree\n",
    "    \"\"\"\n",
    "    n_samples = X.shape[0]\n",
    "    X_poly = np.zeros((n_samples, degree))\n",
    "    \n",
    "    for i in range(degree):\n",
    "        X_poly[:, i] = X.ravel() ** (i + 1)\n",
    "    \n",
    "    return X_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit Models with 1, 2, and 3 Features\n",
    "\n",
    "Following the exact example format provided:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create polynomial features for predictors 1, 2, and 3\n",
    "W_train_1 = create_polynomial_features(W_train, 1)  # Just W\n",
    "W_train_2 = create_polynomial_features(W_train, 2)  # W, W^2\n",
    "W_train_3 = create_polynomial_features(W_train, 3)  # W, W^2, W^3\n",
    "\n",
    "W_test_1 = create_polynomial_features(W_test, 1)\n",
    "W_test_2 = create_polynomial_features(W_test, 2)\n",
    "W_test_3 = create_polynomial_features(W_test, 3)\n",
    "\n",
    "print(\"Feature matrices created:\")\n",
    "print(f\"Predictor 1 - Train: {W_train_1.shape}, Test: {W_test_1.shape}\")\n",
    "print(f\"Predictor 2 - Train: {W_train_2.shape}, Test: {W_test_2.shape}\")\n",
    "print(f\"Predictor 3 - Train: {W_train_3.shape}, Test: {W_test_3.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the three models\n",
    "model_1 = LinearRegression(fit_intercept=False)\n",
    "model_2 = LinearRegression(fit_intercept=False)\n",
    "model_3 = LinearRegression(fit_intercept=False)\n",
    "\n",
    "model_1.fit(W_train_1, y_train.ravel())\n",
    "model_2.fit(W_train_2, y_train.ravel())\n",
    "model_3.fit(W_train_3, y_train.ravel())\n",
    "\n",
    "print(\"Models fitted successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test set\n",
    "y_1_test = model_1.predict(W_test_1)\n",
    "y_2_test = model_2.predict(W_test_2)\n",
    "y_3_test = model_3.predict(W_test_3)\n",
    "\n",
    "print(\"Predictions made on test set\")\n",
    "print(f\"y_1_test shape: {y_1_test.shape}\")\n",
    "print(f\"y_2_test shape: {y_2_test.shape}\")\n",
    "print(f\"y_3_test shape: {y_3_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MSE for each model\n",
    "mse_1_test = np.mean((y_test.ravel() - y_1_test) ** 2)\n",
    "mse_2_test = np.mean((y_test.ravel() - y_2_test) ** 2)\n",
    "mse_3_test = np.mean((y_test.ravel() - y_3_test) ** 2)\n",
    "\n",
    "print(f\"MSE 1: {mse_1_test:.6f}\")\n",
    "print(f\"MSE 2: {mse_2_test:.6f}\")\n",
    "print(f\"MSE 3: {mse_3_test:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R-squared Calculations\n",
    "\n",
    "Using the exact formula provided in the specifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-squared calculations using the exact formula provided\n",
    "R_sq_1_test = 1 - mse_1_test / np.mean((y_test.ravel()-np.mean(y_test.ravel()))** 2)\n",
    "R_sq_2_test = 1 - mse_2_test / np.mean((y_test.ravel()-np.mean(y_test.ravel()))** 2)\n",
    "R_sq_3_test = 1 - mse_3_test / np.mean((y_test.ravel()-np.mean(y_test.ravel()))** 2)\n",
    "\n",
    "print(f'R-squared out of sample of predictor 1 is {R_sq_1_test}')\n",
    "print(f'R-squared out of sample of predictor 2 is {R_sq_2_test}')\n",
    "print(f'R-squared out of sample of predictor 3 is {R_sq_3_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusted R-squared Calculations\n",
    "\n",
    "Using the exact formula provided in the specifications:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusted R-squared calculations using the exact formula provided\n",
    "adj_mse_1_test = 250 / (250-1) * mse_1_test  # Note: using 250 as in the example (though actual test size might differ)\n",
    "adjR_sq_1_test = 1 - adj_mse_1_test / np.mean((y_test.ravel()-np.mean(y_test.ravel()))** 2)\n",
    "\n",
    "adj_mse_2_test = 250 / (250-2) * mse_2_test\n",
    "adjR_sq_2_test = 1 - adj_mse_2_test / np.mean((y_test.ravel()-np.mean(y_test.ravel()))** 2)\n",
    "\n",
    "adj_mse_3_test = 250 / (250-3) * mse_3_test\n",
    "adjR_sq_3_test = 1 - adj_mse_3_test / np.mean((y_test.ravel()-np.mean(y_test.ravel()))** 2)\n",
    "\n",
    "print(f'Adjusted R-squared out of sample of predictor 1 is {adjR_sq_1_test}')\n",
    "print(f'Adjusted R-squared out of sample of predictor 2 is {adjR_sq_2_test}')\n",
    "print(f'Adjusted R-squared out of sample of predictor 3 is {adjR_sq_3_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-Dimensional Analysis: 999 Features for 1000 Observations\n",
    "\n",
    "Demonstrating overfitting with a matrix of 999 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a matrix of 999 features for 1000 observations\n",
    "np.random.seed(42)  # For reproducibility\n",
    "\n",
    "# Create high-dimensional feature matrix\n",
    "n_features_high = 999\n",
    "n_observations = 1000\n",
    "\n",
    "# Use polynomial features of W for the first 50 features, then random features\n",
    "W_high_dim = np.zeros((n_observations, n_features_high))\n",
    "\n",
    "# First 50 features are polynomial features of W\n",
    "W_poly_50 = create_polynomial_features(W, 50)\n",
    "W_high_dim[:, :50] = W_poly_50\n",
    "\n",
    "# Remaining features are random\n",
    "W_high_dim[:, 50:] = np.random.normal(0, 1, (n_observations, n_features_high - 50))\n",
    "\n",
    "print(f\"High-dimensional feature matrix shape: {W_high_dim.shape}\")\n",
    "print(f\"Number of features: {n_features_high}\")\n",
    "print(f\"Number of observations: {n_observations}\")\n",
    "print(f\"Ratio of features to observations: {n_features_high/n_observations:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split high-dimensional data\n",
    "W_train_hd, W_test_hd, y_train_hd, y_test_hd = train_test_split(\n",
    "    W_high_dim, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"High-dim training set: {W_train_hd.shape}\")\n",
    "print(f\"High-dim test set: {W_test_hd.shape}\")\n",
    "print(f\"Features to training observations ratio: {W_train_hd.shape[1]/W_train_hd.shape[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit high-dimensional model\n",
    "try:\n",
    "    model_hd = LinearRegression(fit_intercept=False)\n",
    "    model_hd.fit(W_train_hd, y_train_hd.ravel())\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred_hd = model_hd.predict(W_train_hd)\n",
    "    y_test_pred_hd = model_hd.predict(W_test_hd)\n",
    "    \n",
    "    # Calculate MSE\n",
    "    mse_train_hd = np.mean((y_train_hd.ravel() - y_train_pred_hd) ** 2)\n",
    "    mse_test_hd = np.mean((y_test_hd.ravel() - y_test_pred_hd) ** 2)\n",
    "    \n",
    "    # Calculate R-squared\n",
    "    R_sq_train_hd = 1 - mse_train_hd / np.mean((y_train_hd.ravel() - np.mean(y_train_hd.ravel())) ** 2)\n",
    "    R_sq_test_hd = 1 - mse_test_hd / np.mean((y_test_hd.ravel() - np.mean(y_test_hd.ravel())) ** 2)\n",
    "    \n",
    "    # Calculate Adjusted R-squared for test set\n",
    "    n_test = len(y_test_hd)\n",
    "    n_features = W_test_hd.shape[1]\n",
    "    adj_mse_test_hd = n_test / (n_test - n_features) * mse_test_hd\n",
    "    adjR_sq_test_hd = 1 - adj_mse_test_hd / np.mean((y_test_hd.ravel() - np.mean(y_test_hd.ravel())) ** 2)\n",
    "    \n",
    "    print(\"High-Dimensional Model Results (999 features):\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Training R-squared: {R_sq_train_hd:.6f}\")\n",
    "    print(f\"Test R-squared: {R_sq_test_hd:.6f}\")\n",
    "    print(f\"Test Adjusted R-squared: {adjR_sq_test_hd:.6f}\")\n",
    "    print(f\"Training MSE: {mse_train_hd:.6f}\")\n",
    "    print(f\"Test MSE: {mse_test_hd:.6f}\")\n",
    "    print(f\"Overfitting Gap (Train - Test R²): {R_sq_train_hd - R_sq_test_hd:.6f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error with high-dimensional model: {e}\")\n",
    "    print(\"This demonstrates the challenge of fitting models with too many features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comparison of different models\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Plot 1: True function vs data\n",
    "axes[0].scatter(W, y, alpha=0.5, s=20, c='lightblue', label='Observed data')\n",
    "W_sorted = np.sort(W, axis=0)\n",
    "f_sorted = np.exp(4 * W_sorted) - 1\n",
    "axes[0].plot(W_sorted, f_sorted, 'r-', linewidth=2, label='True function: exp(4W) - 1')\n",
    "axes[0].set_xlabel('W')\n",
    "axes[0].set_ylabel('y')\n",
    "axes[0].set_title('Data Generating Process')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: R-squared comparison\n",
    "models = ['1 feature', '2 features', '3 features']\n",
    "r2_values = [R_sq_1_test, R_sq_2_test, R_sq_3_test]\n",
    "adj_r2_values = [adjR_sq_1_test, adjR_sq_2_test, adjR_sq_3_test]\n",
    "\n",
    "x_pos = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "axes[1].bar(x_pos - width/2, r2_values, width, label='R-squared', alpha=0.8)\n",
    "axes[1].bar(x_pos + width/2, adj_r2_values, width, label='Adjusted R-squared', alpha=0.8)\n",
    "axes[1].set_xlabel('Model Complexity')\n",
    "axes[1].set_ylabel('R-squared Value')\n",
    "axes[1].set_title('R-squared vs Adjusted R-squared')\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels(models)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Overfitting Analysis\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Polynomial Features**: As we increase from 1 to 3 polynomial features, both R-squared and Adjusted R-squared improve, showing that the polynomial features help capture the exponential relationship.\n",
    "\n",
    "2. **High-Dimensional Problem**: With 999 features for 1000 observations, we demonstrate extreme overfitting where:\n",
    "   - Training R-squared approaches 1.0 (perfect fit)\n",
    "   - Test R-squared is much lower (poor generalization)\n",
    "   - Adjusted R-squared can become negative or very poor\n",
    "\n",
    "3. **Overfitting Indicators**:\n",
    "   - Large gap between training and test performance\n",
    "   - Perfect or near-perfect training fit with poor test performance\n",
    "   - Negative or degraded adjusted R-squared values\n",
    "\n",
    "### Practical Implications:\n",
    "\n",
    "- **Model Selection**: Always validate models on out-of-sample data\n",
    "- **Feature Selection**: More features aren't always better\n",
    "- **Regularization**: Consider Ridge/Lasso regression for high-dimensional problems\n",
    "- **Cross-Validation**: Use proper validation techniques to assess generalization\n",
    "\n",
    "The exponential data generating process **f_X = exp(4*X) - 1** creates a challenging nonlinear relationship that polynomial approximations try to capture, but adding too many features leads to overfitting rather than better approximation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}