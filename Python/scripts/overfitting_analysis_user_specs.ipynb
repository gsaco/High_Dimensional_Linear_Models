{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting Analysis - High Dimensional Linear Models\n",
    "\n",
    "This notebook demonstrates overfitting in high-dimensional linear models using the specified data generating process.\n",
    "\n",
    "**Data Generating Process:** f_X = exp(4 * X) - 1\n",
    "\n",
    "We analyze how adding polynomial features leads to overfitting by examining R-squared and Adjusted R-squared metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "\n",
    "Using the specified libraries as requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation\n",
    "\n",
    "Following the exact specifications from the class:\n",
    "- Generate W from uniform distribution [0,1] and sort\n",
    "- Generate error term e from normal distribution N(0,1)\n",
    "- Use data generating process: f_X = exp(4 * X) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate W as specified\n",
    "W = np.random.uniform(0, 1, 1000)\n",
    "W.sort()\n",
    "W = W.reshape(-1, 1)\n",
    "print(\"W shape:\", W.shape)\n",
    "print(\"W range: [{:.4f}, {:.4f}]\".format(W.min(), W.max()))\n",
    "print(\"W:\")\n",
    "print(W[:10])  # Print first 10 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate error term e as specified\n",
    "e = np.random.normal(0, 1, 1000)\n",
    "e = e.reshape(-1, 1)\n",
    "print(\"e shape:\", e.shape)\n",
    "print(\"e:\")\n",
    "print(e[:10])  # Print first 10 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate y using the specified function: f_X = exp(4 * X) - 1\n",
    "f_X = np.exp(4 * W) - 1\n",
    "y = f_X + e\n",
    "\n",
    "print(\"f_X shape:\", f_X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"f_X range: [{:.4f}, {:.4f}]\".format(f_X.min(), f_X.max()))\n",
    "print(\"y range: [{:.4f}, {:.4f}]\".format(y.min(), y.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the Data Generating Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the true relationship and data\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot 1: True function\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(W, f_X, 'b-', linewidth=2, label='f_X = exp(4*X) - 1')\n",
    "plt.xlabel('X (W)')\n",
    "plt.ylabel('f_X')\n",
    "plt.title('True Data Generating Function')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Data with noise\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(W, y, alpha=0.6, s=10, c='red', label='y = f_X + e')\n",
    "plt.plot(W, f_X, 'b-', linewidth=2, label='True function')\n",
    "plt.xlabel('X (W)')\n",
    "plt.ylabel('y')\n",
    "plt.title('Observed Data with Noise')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "\n",
    "Split the data into training (750 observations) and test (250 observations) sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "W_train, W_test, y_train, y_test = train_test_split(\n",
    "    W, y, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(W_train)}\")\n",
    "print(f\"Test set size: {len(W_test)}\")\n",
    "print(f\"Training W range: [{W_train.min():.4f}, {W_train.max():.4f}]\")\n",
    "print(f\"Test W range: [{W_test.min():.4f}, {W_test.max():.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions for Polynomial Features and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_polynomial_features(X, n_features):\n",
    "    \"\"\"\n",
    "    Create polynomial features X, X^2, X^3, ..., X^n_features\n",
    "    \"\"\"\n",
    "    n_samples = X.shape[0]\n",
    "    X_poly = np.zeros((n_samples, n_features))\n",
    "    \n",
    "    for i in range(n_features):\n",
    "        X_poly[:, i] = (X.ravel()) ** (i + 1)\n",
    "    \n",
    "    return X_poly\n",
    "\n",
    "def calculate_mse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate Mean Squared Error\n",
    "    \"\"\"\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "print(\"Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting Analysis\n",
    "\n",
    "We'll fit linear models with different numbers of polynomial features (1, 2, 3, ..., up to 999) to demonstrate overfitting.\n",
    "\n",
    "For each model, we'll calculate:\n",
    "1. R-squared on test data\n",
    "2. Adjusted R-squared on test data\n",
    "\n",
    "Using the exact formulas provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of features to test\n",
    "# We'll test models with 1, 2, 3, 5, 10, 20, 50, 100, 200, 500 features\n",
    "# (avoiding 999 initially to prevent computational issues)\n",
    "feature_counts = [1, 2, 3, 5, 10, 20, 50, 100, 200, 500]\n",
    "\n",
    "# Storage for results\n",
    "results = []\n",
    "\n",
    "print(\"Starting overfitting analysis...\")\n",
    "print(\"Features | R² (test) | Adj R² (test) | MSE (test)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for n_features in feature_counts:\n",
    "    # Skip if we don't have enough training samples\n",
    "    if n_features >= len(W_train):\n",
    "        print(f\"{n_features:8d} | Skipped (too many features for training set)\")\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Create polynomial features for training and test sets\n",
    "        W_train_poly = create_polynomial_features(W_train, n_features)\n",
    "        W_test_poly = create_polynomial_features(W_test, n_features)\n",
    "        \n",
    "        # Fit linear regression model (no intercept as specified)\n",
    "        model = LinearRegression(fit_intercept=False)\n",
    "        model.fit(W_train_poly, y_train.ravel())\n",
    "        \n",
    "        # Make predictions on test set\n",
    "        y_test_pred = model.predict(W_test_poly)\n",
    "        \n",
    "        # Calculate MSE on test set\n",
    "        mse_test = calculate_mse(y_test.ravel(), y_test_pred)\n",
    "        \n",
    "        # Calculate R-squared on test set using the specified formula\n",
    "        R_sq_test = 1 - mse_test / np.mean((y_test.ravel() - np.mean(y_test.ravel())) ** 2)\n",
    "        \n",
    "        # Calculate Adjusted R-squared on test set using the specified formula\n",
    "        adj_mse_test = len(W_test) / (len(W_test) - n_features) * mse_test\n",
    "        adjR_sq_test = 1 - adj_mse_test / np.mean((y_test.ravel() - np.mean(y_test.ravel())) ** 2)\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'n_features': n_features,\n",
    "            'r2_test': R_sq_test,\n",
    "            'adj_r2_test': adjR_sq_test,\n",
    "            'mse_test': mse_test\n",
    "        })\n",
    "        \n",
    "        print(f\"{n_features:8d} | {R_sq_test:9.4f} | {adjR_sq_test:10.4f} | {mse_test:10.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"{n_features:8d} | Error: {str(e)[:30]}...\")\n",
    "\n",
    "print(f\"\\nCompleted analysis for {len(results)} models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example with First Three Predictors\n",
    "\n",
    "Let's demonstrate the exact calculation method for the first three predictors as shown in the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit models with 1, 2, and 3 features specifically\n",
    "models_123 = {}\n",
    "predictions_123 = {}\n",
    "mse_123 = {}\n",
    "\n",
    "for i in [1, 2, 3]:\n",
    "    # Create polynomial features\n",
    "    W_train_poly = create_polynomial_features(W_train, i)\n",
    "    W_test_poly = create_polynomial_features(W_test, i)\n",
    "    \n",
    "    # Fit model\n",
    "    model = LinearRegression(fit_intercept=False)\n",
    "    model.fit(W_train_poly, y_train.ravel())\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = model.predict(W_test_poly)\n",
    "    \n",
    "    # Calculate MSE\n",
    "    mse = calculate_mse(y_test.ravel(), y_pred)\n",
    "    \n",
    "    # Store results\n",
    "    models_123[i] = model\n",
    "    predictions_123[i] = y_pred\n",
    "    mse_123[i] = mse\n",
    "\n",
    "# Extract MSE values\n",
    "mse_1_test = mse_123[1]\n",
    "mse_2_test = mse_123[2]\n",
    "mse_3_test = mse_123[3]\n",
    "\n",
    "# Extract predictions\n",
    "y_1_test = predictions_123[1]\n",
    "y_2_test = predictions_123[2]\n",
    "y_3_test = predictions_123[3]\n",
    "\n",
    "print(f\"MSE for 1 feature: {mse_1_test:.6f}\")\n",
    "print(f\"MSE for 2 features: {mse_2_test:.6f}\")\n",
    "print(f\"MSE for 3 features: {mse_3_test:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R-squared Calculations Using Exact Formula\n",
    "\n",
    "Using the exact formulas provided in the problem statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R-squared calculations using the exact formula provided\n",
    "R_sq_1_test = 1 - mse_1_test / np.mean((y_test.ravel() - np.mean(y_test.ravel()))** 2)\n",
    "R_sq_2_test = 1 - mse_2_test / np.mean((y_test.ravel() - np.mean(y_test.ravel()))** 2)\n",
    "R_sq_3_test = 1 - mse_3_test / np.mean((y_test.ravel() - np.mean(y_test.ravel()))** 2)\n",
    "\n",
    "print(f'R-squared out of sample of predictor 1 is {R_sq_1_test:.6f}')\n",
    "print(f'R-squared out of sample of predictor 2 is {R_sq_2_test:.6f}')\n",
    "print(f'R-squared out of sample of predictor 3 is {R_sq_3_test:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusted R-squared Calculations Using Exact Formula\n",
    "\n",
    "Using the exact formulas provided in the problem statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusted R-squared calculations using the exact formula provided\n",
    "# Note: Using 250 as the test set size as shown in the example\n",
    "test_size = len(y_test)\n",
    "print(f\"Test set size: {test_size}\")\n",
    "\n",
    "adj_mse_1_test = test_size / (test_size - 1) * mse_1_test  # 1 feature\n",
    "adjR_sq_1_test = 1 - adj_mse_1_test / np.mean((y_test.ravel() - np.mean(y_test.ravel()))** 2)\n",
    "\n",
    "adj_mse_2_test = test_size / (test_size - 2) * mse_2_test  # 2 features\n",
    "adjR_sq_2_test = 1 - adj_mse_2_test / np.mean((y_test.ravel() - np.mean(y_test.ravel()))** 2)\n",
    "\n",
    "adj_mse_3_test = test_size / (test_size - 3) * mse_3_test  # 3 features\n",
    "adjR_sq_3_test = 1 - adj_mse_3_test / np.mean((y_test.ravel() - np.mean(y_test.ravel()))** 2)\n",
    "\n",
    "print(f'Adjusted R-squared out of sample of predictor 1 is {adjR_sq_1_test:.6f}')\n",
    "print(f'Adjusted R-squared out of sample of predictor 2 is {adjR_sq_2_test:.6f}')\n",
    "print(f'Adjusted R-squared out of sample of predictor 3 is {adjR_sq_3_test:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data for plotting\n",
    "if len(results) > 0:\n",
    "    features = [r['n_features'] for r in results]\n",
    "    r2_values = [r['r2_test'] for r in results]\n",
    "    adj_r2_values = [r['adj_r2_test'] for r in results]\n",
    "    \n",
    "    # Create plots\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Plot 1: R-squared vs number of features\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(features, r2_values, 'bo-', linewidth=2, markersize=6)\n",
    "    plt.xlabel('Number of Features')\n",
    "    plt.ylabel('R-squared (Test Set)')\n",
    "    plt.title('Test Set R-squared vs Number of Features')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xscale('log')\n",
    "    \n",
    "    # Plot 2: Adjusted R-squared vs number of features\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(features, adj_r2_values, 'ro-', linewidth=2, markersize=6)\n",
    "    plt.xlabel('Number of Features')\n",
    "    plt.ylabel('Adjusted R-squared (Test Set)')\n",
    "    plt.title('Test Set Adjusted R-squared vs Number of Features')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xscale('log')\n",
    "    \n",
    "    # Plot 3: Both metrics together\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(features, r2_values, 'bo-', linewidth=2, markersize=6, label='R-squared')\n",
    "    plt.plot(features, adj_r2_values, 'ro-', linewidth=2, markersize=6, label='Adjusted R-squared')\n",
    "    plt.xlabel('Number of Features')\n",
    "    plt.ylabel('Test Set Performance')\n",
    "    plt.title('Comparison of R-squared Metrics')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.xscale('log')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No results to plot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: Demonstrating Overfitting with High-Dimensional Features\n",
    "\n",
    "Let's create a matrix with 999 features for 1000 observations to demonstrate extreme overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a high-dimensional feature matrix (999 features for 1000 observations)\n",
    "print(\"Creating high-dimensional feature matrix (999 features)...\")\n",
    "\n",
    "# Generate 999 random features for demonstration\n",
    "np.random.seed(42)\n",
    "n_obs = 1000\n",
    "n_features_high = 999\n",
    "\n",
    "# Create a matrix of random features\n",
    "X_high_dim = np.random.normal(0, 1, (n_obs, n_features_high))\n",
    "\n",
    "# Also include our original W as the first feature, and polynomial features of W\n",
    "X_high_dim[:, :50] = create_polynomial_features(W, 50)  # First 50 features are polynomial features of W\n",
    "\n",
    "print(f\"High-dimensional feature matrix shape: {X_high_dim.shape}\")\n",
    "print(f\"Ratio of features to observations: {n_features_high/n_obs:.3f}\")\n",
    "\n",
    "# Use our y variable (still based on f_X = exp(4*X) - 1)\n",
    "y_high_dim = y.ravel()\n",
    "\n",
    "print(f\"Target variable shape: {y_high_dim.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the high-dimensional data\n",
    "X_train_hd, X_test_hd, y_train_hd, y_test_hd = train_test_split(\n",
    "    X_high_dim, y_high_dim, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"High-dim training set: {X_train_hd.shape}\")\n",
    "print(f\"High-dim test set: {X_test_hd.shape}\")\n",
    "print(f\"Training observations: {len(y_train_hd)}\")\n",
    "print(f\"Test observations: {len(y_test_hd)}\")\n",
    "print(f\"Features: {X_train_hd.shape[1]}\")\n",
    "print(f\"Ratio of features to training observations: {X_train_hd.shape[1]/len(y_train_hd):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit linear regression with 999 features\n",
    "print(\"Fitting high-dimensional linear regression...\")\n",
    "\n",
    "try:\n",
    "    # Fit the model (this will likely overfit severely)\n",
    "    model_hd = LinearRegression(fit_intercept=False)\n",
    "    model_hd.fit(X_train_hd, y_train_hd)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_train_pred_hd = model_hd.predict(X_train_hd)\n",
    "    y_test_pred_hd = model_hd.predict(X_test_hd)\n",
    "    \n",
    "    # Calculate MSE\n",
    "    mse_train_hd = calculate_mse(y_train_hd, y_train_pred_hd)\n",
    "    mse_test_hd = calculate_mse(y_test_hd, y_test_pred_hd)\n",
    "    \n",
    "    # Calculate R-squared\n",
    "    r2_train_hd = 1 - mse_train_hd / np.mean((y_train_hd - np.mean(y_train_hd)) ** 2)\n",
    "    r2_test_hd = 1 - mse_test_hd / np.mean((y_test_hd - np.mean(y_test_hd)) ** 2)\n",
    "    \n",
    "    # Calculate Adjusted R-squared\n",
    "    n_train = len(y_train_hd)\n",
    "    n_test = len(y_test_hd)\n",
    "    n_features = X_train_hd.shape[1]\n",
    "    \n",
    "    adj_mse_test_hd = n_test / (n_test - n_features) * mse_test_hd\n",
    "    adj_r2_test_hd = 1 - adj_mse_test_hd / np.mean((y_test_hd - np.mean(y_test_hd)) ** 2)\n",
    "    \n",
    "    print(\"\\nHigh-Dimensional Model Results (999 features):\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Training R-squared: {r2_train_hd:.6f}\")\n",
    "    print(f\"Test R-squared: {r2_test_hd:.6f}\")\n",
    "    print(f\"Test Adjusted R-squared: {adj_r2_test_hd:.6f}\")\n",
    "    print(f\"Training MSE: {mse_train_hd:.6f}\")\n",
    "    print(f\"Test MSE: {mse_test_hd:.6f}\")\n",
    "    print(f\"Overfitting Gap (Train R² - Test R²): {r2_train_hd - r2_test_hd:.6f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error fitting high-dimensional model: {e}\")\n",
    "    print(\"This is expected when we have too many features relative to observations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Conclusions\n",
    "\n",
    "This analysis demonstrates the overfitting phenomenon in high-dimensional linear models:\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Training vs. Test Performance**: As we add more polynomial features, models can achieve higher R-squared on training data but often perform worse on test data.\n",
    "\n",
    "2. **Adjusted R-squared**: Unlike regular R-squared, adjusted R-squared can become negative when the model performs very poorly, indicating that the model is worse than simply using the mean.\n",
    "\n",
    "3. **High-Dimensional Problem**: With 999 features and 1000 observations, we approach the extreme case where the number of parameters nearly equals the number of observations, leading to severe overfitting.\n",
    "\n",
    "### Overfitting Indicators:\n",
    "- Large gap between training and test R-squared\n",
    "- Declining test performance as model complexity increases\n",
    "- Negative adjusted R-squared values\n",
    "\n",
    "### Practical Implications:\n",
    "- Always use proper validation techniques\n",
    "- Consider regularization methods (Ridge, Lasso, Elastic Net)\n",
    "- Monitor both training and validation performance\n",
    "- Be cautious of models with many features relative to observations\n",
    "\n",
    "The exponential data generating process (f_X = exp(4*X) - 1) creates a challenging nonlinear relationship that polynomial features attempt to approximate, but adding too many features leads to overfitting rather than better approximation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}