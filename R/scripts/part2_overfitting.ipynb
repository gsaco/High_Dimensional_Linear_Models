{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 - Part 2: Overfitting Analysis\n",
    "## Overfitting (8 points)\n",
    "\n",
    "This notebook analyzes overfitting using a procedure similar to simulation.ipynb. We use a simple data generating process and study how R-squared measures change with model complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Load required libraries\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(tidyr)\n",
    "\n",
    "# Set options for better output display\n",
    "options(digits = 6)\n",
    "options(scipen = 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation\n",
    "\n",
    "Following the simulation.ipynb approach, we generate data with a convenient slope (PGD) for all three languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "generate_data <- function(n = 1000, seed = 42) {\n",
    "  #' Generate data following the specification similar to simulation.ipynb.\n",
    "  #' Two variables X and Y, intercept parameter is zero.\n",
    "  #'\n",
    "  #' @param n Sample size (default: 1000)\n",
    "  #' @param seed Random seed for reproducibility (42)\n",
    "  #'\n",
    "  #' @return List containing X (feature matrix) and y (target variable)\n",
    "  \n",
    "  set.seed(seed)\n",
    "  \n",
    "  # Generate X from uniform distribution like in simulation.ipynb\n",
    "  X_raw <- runif(n, 0, 1)\n",
    "  X_raw <- sort(X_raw)  # Sort like in simulation\n",
    "  X <- matrix(X_raw, nrow = n, ncol = 1)\n",
    "  \n",
    "  # Generate error term\n",
    "  e <- rnorm(n, 0, 1)\n",
    "  \n",
    "  # Generate y with no intercept (as requested)\n",
    "  # True relationship: y = 2*X + e (convenient slope for all languages)\n",
    "  beta_true <- 2.0\n",
    "  y <- beta_true * X[, 1] + e\n",
    "  \n",
    "  return(list(X = X, y = y))\n",
    "}\n",
    "\n",
    "# Generate the data\n",
    "data <- generate_data(n = 1000, seed = 42)\n",
    "X <- data$X\n",
    "y <- data$y\n",
    "\n",
    "cat(sprintf(\"Generated data with n=%d observations\\n\", length(y)))\n",
    "cat(\"True relationship: y = 2*X + e (convenient slope = 2.0)\\n\")\n",
    "cat(sprintf(\"X range: [%.4f, %.4f]\\n\", min(X), max(X)))\n",
    "cat(sprintf(\"y range: [%.4f, %.4f]\\n\", min(y), max(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "create_polynomial_features <- function(X, n_features) {\n",
    "  #' Create polynomial features up to n_features.\n",
    "  #'\n",
    "  #' @param X Original feature matrix (n x 1)\n",
    "  #' @param n_features Number of features to create\n",
    "  #'\n",
    "  #' @return Extended feature matrix with polynomial features\n",
    "  \n",
    "  n_samples <- nrow(X)\n",
    "  X_poly <- matrix(0, nrow = n_samples, ncol = n_features)\n",
    "  \n",
    "  for (i in 1:n_features) {\n",
    "    X_poly[, i] <- X[, 1]^i  # x^1, x^2, x^3, etc.\n",
    "  }\n",
    "  \n",
    "  return(X_poly)\n",
    "}\n",
    "\n",
    "calculate_adjusted_r2 <- function(r2, n, k) {\n",
    "  #' Calculate adjusted R-squared.\n",
    "  #'\n",
    "  #' Adjusted R² = 1 - [(1 - R²)(n - 1) / (n - k - 1)]\n",
    "  #'\n",
    "  #' @param r2 R-squared value\n",
    "  #' @param n Sample size\n",
    "  #' @param k Number of features (excluding intercept)\n",
    "  #'\n",
    "  #' @return Adjusted R-squared\n",
    "  \n",
    "  if (n - k - 1 <= 0) {\n",
    "    return(NA)\n",
    "  }\n",
    "  \n",
    "  adj_r2 <- 1 - ((1 - r2) * (n - 1) / (n - k - 1))\n",
    "  return(adj_r2)\n",
    "}\n",
    "\n",
    "r2_score <- function(y_true, y_pred) {\n",
    "  #' Calculate R-squared score.\n",
    "  ss_res <- sum((y_true - y_pred)^2)\n",
    "  ss_tot <- sum((y_true - mean(y_true))^2)\n",
    "  return(1 - (ss_res / ss_tot))\n",
    "}\n",
    "\n",
    "train_test_split <- function(X, y, test_size = 0.25, random_state = 42) {\n",
    "  #' Split data into training and testing sets.\n",
    "  set.seed(random_state)\n",
    "  n <- length(y)\n",
    "  n_test <- round(n * test_size)\n",
    "  indices <- sample(1:n, n)\n",
    "  \n",
    "  test_indices <- indices[1:n_test]\n",
    "  train_indices <- indices[(n_test + 1):n]\n",
    "  \n",
    "  return(list(\n",
    "    X_train = X[train_indices, , drop = FALSE],\n",
    "    X_test = X[test_indices, , drop = FALSE],\n",
    "    y_train = y[train_indices],\n",
    "    y_test = y[test_indices]\n",
    "  ))\n",
    "}\n",
    "\n",
    "# Test the functions\n",
    "X_poly_example <- create_polynomial_features(X, 5)\n",
    "cat(sprintf(\"Original X shape: (%d, %d)\\n\", nrow(X), ncol(X)))\n",
    "cat(sprintf(\"Polynomial features (5 features) shape: (%d, %d)\\n\", nrow(X_poly_example), ncol(X_poly_example)))\n",
    "cat(sprintf(\"Example adjusted R²: %.4f\\n\", calculate_adjusted_r2(0.8, 1000, 5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting Analysis\n",
    "\n",
    "Test models with different numbers of polynomial features: 1, 2, 5, 10, 20, 50, 100, 200, 500, 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "overfitting_analysis <- function() {\n",
    "  #' Main function to perform overfitting analysis.\n",
    "  \n",
    "  # Number of features to test (as specified)\n",
    "  n_features_list <- c(1, 2, 5, 10, 20, 50, 100, 200, 500, 1000)\n",
    "  \n",
    "  # Storage for results\n",
    "  results <- data.frame(\n",
    "    n_features = integer(),\n",
    "    r2_full = numeric(),\n",
    "    adj_r2_full = numeric(),\n",
    "    r2_out_of_sample = numeric()\n",
    "  )\n",
    "  \n",
    "  cat(\"Analyzing overfitting for different numbers of features...\\n\")\n",
    "  cat(\"Features | R² (full) | Adj R² (full) | R² (out-of-sample)\\n\")\n",
    "  cat(paste(rep(\"-\", 60), collapse = \"\"), \"\\n\")\n",
    "  \n",
    "  for (n_feat in n_features_list) {\n",
    "    tryCatch({\n",
    "      # Create polynomial features\n",
    "      X_poly <- create_polynomial_features(X, n_feat)\n",
    "      \n",
    "      # Split data into train/test (75%/25%)\n",
    "      split_data <- train_test_split(X_poly, y, test_size = 0.25, random_state = 42)\n",
    "      X_train <- split_data$X_train\n",
    "      X_test <- split_data$X_test\n",
    "      y_train <- split_data$y_train\n",
    "      y_test <- split_data$y_test\n",
    "      \n",
    "      # Fit model on full sample (no intercept as requested)\n",
    "      # Using solve() for OLS: beta = (X'X)^(-1) X'y\n",
    "      if (n_feat >= nrow(X_poly)) {\n",
    "        # When n_features >= n_samples, use regularized solution\n",
    "        lambda <- 1e-6\n",
    "        beta_full <- solve(t(X_poly) %*% X_poly + lambda * diag(n_feat), t(X_poly) %*% y)\n",
    "      } else {\n",
    "        beta_full <- solve(t(X_poly) %*% X_poly, t(X_poly) %*% y)\n",
    "      }\n",
    "      y_pred_full <- X_poly %*% beta_full\n",
    "      r2_full <- r2_score(y, y_pred_full)\n",
    "      \n",
    "      # Calculate adjusted R²\n",
    "      adj_r2_full <- calculate_adjusted_r2(r2_full, length(y), n_feat)\n",
    "      \n",
    "      # Fit model on training data and predict on test data\n",
    "      if (n_feat >= nrow(X_train)) {\n",
    "        # When n_features >= n_samples, use regularized solution\n",
    "        lambda <- 1e-6\n",
    "        beta_train <- solve(t(X_train) %*% X_train + lambda * diag(n_feat), t(X_train) %*% y_train)\n",
    "      } else {\n",
    "        beta_train <- solve(t(X_train) %*% X_train, t(X_train) %*% y_train)\n",
    "      }\n",
    "      y_pred_test <- X_test %*% beta_train\n",
    "      r2_out_of_sample <- r2_score(y_test, y_pred_test)\n",
    "      \n",
    "      # Store results\n",
    "      results <- rbind(results, data.frame(\n",
    "        n_features = n_feat,\n",
    "        r2_full = r2_full,\n",
    "        adj_r2_full = adj_r2_full,\n",
    "        r2_out_of_sample = r2_out_of_sample\n",
    "      ))\n",
    "      \n",
    "      cat(sprintf(\"%8d | %9.4f | %12.4f | %17.4f\\n\", n_feat, r2_full, adj_r2_full, r2_out_of_sample))\n",
    "      \n",
    "    }, error = function(e) {\n",
    "      cat(sprintf(\"Error with %d features: %s\\n\", n_feat, e$message))\n",
    "      # Still append to maintain consistency\n",
    "      results <<- rbind(results, data.frame(\n",
    "        n_features = n_feat,\n",
    "        r2_full = NA,\n",
    "        adj_r2_full = NA,\n",
    "        r2_out_of_sample = NA\n",
    "      ))\n",
    "    })\n",
    "  }\n",
    "  \n",
    "  return(results)\n",
    "}\n",
    "\n",
    "# Run the analysis\n",
    "results_df <- overfitting_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Create three separate graphs for each R-squared measure as requested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "create_separate_plots <- function(df_results) {\n",
    "  #' Create three separate plots for R-squared analysis.\n",
    "  \n",
    "  # Filter out NA values for plotting\n",
    "  df_clean <- df_results[complete.cases(df_results), ]\n",
    "  \n",
    "  # Create individual plots\n",
    "  \n",
    "  # Plot 1: R-squared (full sample)\n",
    "  p1 <- ggplot(df_clean, aes(x = n_features, y = r2_full)) +\n",
    "    geom_line(size = 1, color = \"blue\") +\n",
    "    geom_point(size = 3, color = \"blue\") +\n",
    "    scale_x_log10() +\n",
    "    ylim(0, 1) +\n",
    "    labs(\n",
    "      title = \"R-squared on Full Sample vs Number of Features\",\n",
    "      x = \"Number of Features (log scale)\",\n",
    "      y = \"R-squared\"\n",
    "    ) +\n",
    "    theme_bw() +\n",
    "    theme(\n",
    "      plot.title = element_text(size = 12, face = \"bold\"),\n",
    "      panel.grid.minor = element_line(alpha = 0.3)\n",
    "    )\n",
    "  \n",
    "  print(p1)\n",
    "  \n",
    "  # Plot 2: Adjusted R-squared (full sample)\n",
    "  p2 <- ggplot(df_clean, aes(x = n_features, y = adj_r2_full)) +\n",
    "    geom_line(size = 1, color = \"green\") +\n",
    "    geom_point(size = 3, color = \"green\", shape = 15) +\n",
    "    scale_x_log10() +\n",
    "    labs(\n",
    "      title = \"Adjusted R-squared on Full Sample vs Number of Features\",\n",
    "      x = \"Number of Features (log scale)\",\n",
    "      y = \"Adjusted R-squared\"\n",
    "    ) +\n",
    "    theme_bw() +\n",
    "    theme(\n",
    "      plot.title = element_text(size = 12, face = \"bold\"),\n",
    "      panel.grid.minor = element_line(alpha = 0.3)\n",
    "    )\n",
    "  \n",
    "  print(p2)\n",
    "  \n",
    "  # Plot 3: Out-of-sample R-squared\n",
    "  p3 <- ggplot(df_clean, aes(x = n_features, y = r2_out_of_sample)) +\n",
    "    geom_line(size = 1, color = \"red\") +\n",
    "    geom_point(size = 3, color = \"red\", shape = 17) +\n",
    "    scale_x_log10() +\n",
    "    labs(\n",
    "      title = \"Out-of-Sample R-squared vs Number of Features\",\n",
    "      x = \"Number of Features (log scale)\",\n",
    "      y = \"Out-of-Sample R-squared\"\n",
    "    ) +\n",
    "    theme_bw() +\n",
    "    theme(\n",
    "      plot.title = element_text(size = 12, face = \"bold\"),\n",
    "      panel.grid.minor = element_line(alpha = 0.3)\n",
    "    )\n",
    "  \n",
    "  print(p3)\n",
    "  \n",
    "  return(list(p1 = p1, p2 = p2, p3 = p3))\n",
    "}\n",
    "\n",
    "# Create the plots\n",
    "plots <- create_separate_plots(results_df)\n",
    "\n",
    "cat(\"\\nThree separate plots created showing:\\n\")\n",
    "cat(\"1. R² (Full Sample): Shows monotonic increase\\n\")\n",
    "cat(\"2. Adjusted R² (Full Sample): Shows peak and decline due to complexity penalty\\n\")\n",
    "cat(\"3. R² (Out-of-Sample): Shows the classic overfitting pattern\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Display complete results\n",
    "cat(\"\\n=== COMPLETE RESULTS TABLE ===\\n\")\n",
    "print(results_df, row.names = FALSE, digits = 4)\n",
    "\n",
    "# Find optimal complexity\n",
    "valid_results <- results_df[complete.cases(results_df), ]\n",
    "if (nrow(valid_results) > 0) {\n",
    "  optimal_adj_r2_idx <- which.max(valid_results$adj_r2_full)\n",
    "  optimal_oos_r2_idx <- which.max(valid_results$r2_out_of_sample)\n",
    "  \n",
    "  cat(\"\\n=== OPTIMAL MODEL COMPLEXITY ===\\n\")\n",
    "  cat(sprintf(\"By Adjusted R²: %d features\\n\", valid_results$n_features[optimal_adj_r2_idx]))\n",
    "  cat(sprintf(\"By Out-of-Sample R²: %d features\\n\", valid_results$n_features[optimal_oos_r2_idx]))\n",
    "}\n",
    "\n",
    "cat(\"\\n=== INSIGHTS ===\\n\")\n",
    "cat(\"✅ This analysis demonstrates the classic bias-variance tradeoff\\n\")\n",
    "cat(\"📈 R² (Full Sample) increases monotonically with model complexity\\n\")\n",
    "cat(\"📊 Adjusted R² peaks early and then declines due to complexity penalty\\n\")\n",
    "cat(\"📉 Out-of-Sample R² shows the inverted U-shape characteristic of overfitting\\n\")\n",
    "cat(\"🎯 True model has only 1 feature (y = 2*X + e), but polynomial terms can help initially\\n\")\n",
    "cat(\"⚠️ High-dimensional models (many features) lead to severe overfitting\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create output directory and save results\n",
    "output_dir <- \"../output\"\n",
    "if (!dir.exists(output_dir)) {\n",
    "  dir.create(output_dir, recursive = TRUE)\n",
    "}\n",
    "\n",
    "# Save results\n",
    "write.csv(results_df, file.path(output_dir, \"overfitting_results_r.csv\"), row.names = FALSE)\n",
    "cat(sprintf(\"Results saved to %s/overfitting_results_r.csv\\n\", output_dir))\n",
    "\n",
    "cat(\"\\n🎉 R overfitting analysis complete!\\n\")\n",
    "cat(\"Data generation follows simulation.ipynb approach with:\\n\")\n",
    "cat(\"- X ~ Uniform(0,1), sorted, n=1000\\n\")\n",
    "cat(\"- e ~ Normal(0,1)\\n\")\n",
    "cat(\"- y = 2*X + e (convenient slope = 2.0)\\n\")\n",
    "cat(\"- No intercept (as requested)\\n\")\n",
    "cat(\"- Seed = 42 for reproducibility\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}