{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 - Part 1: Frisch-Waugh-Lovell (FWL) Theorem\n",
    "## Math (3 points)\n",
    "\n",
    "This notebook contains the mathematical proof and numerical verification of the Frisch-Waugh-Lovell theorem implemented in R.\n",
    "\n",
    "The FWL theorem is a fundamental result in econometrics that shows how to isolate the effect of specific variables by \"partialling out\" the effects of other variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Load required libraries\n",
    "library(MASS)  # For matrix operations\n",
    "\n",
    "# Set options for better output display\n",
    "options(digits = 6)\n",
    "options(scipen = 999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical Proof of the FWL Theorem\n",
    "\n",
    "The FWL theorem states that the OLS estimate of β₁ in the regression of y on [X₁ X₂] is equal to the OLS estimate obtained from the following two-step procedure:\n",
    "\n",
    "1. Regress y on X₂ and obtain the residuals ỹ = M_{X₂}y, where M_{X₂} = I - X₂(X₂'X₂)⁻¹X₂'\n",
    "2. Regress X₁ on X₂ and obtain the residuals X̃₁ = M_{X₂}X₁\n",
    "3. Regress ỹ on X̃₁ and show that the resulting coefficient vector is equal to β̂₁ from the full regression.\n",
    "\n",
    "Formally, we need to show that: β̂₁ = (X̃₁'X̃₁)⁻¹X̃₁'ỹ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "fwl_theorem_proof <- function() {\n",
    "  #' Mathematical proof of the Frisch-Waugh-Lovell theorem.\n",
    "  \n",
    "  cat(\"=== FRISCH-WAUGH-LOVELL THEOREM PROOF ===\\n\\n\")\n",
    "  \n",
    "  cat(\"Mathematical Proof:\\n\")\n",
    "  cat(\"==================\\n\")\n",
    "  cat(\"\\n\")\n",
    "  cat(\"Consider the linear regression model:\\n\")\n",
    "  cat(\"y = X₁β₁ + X₂β₂ + u\\n\")\n",
    "  cat(\"\\n\")\n",
    "  cat(\"Where:\\n\")\n",
    "  cat(\"- y is an n×1 vector of outcomes\\n\")\n",
    "  cat(\"- X₁ is an n×k₁ matrix of regressors of interest\\n\")\n",
    "  cat(\"- X₂ is an n×k₂ matrix of control variables\\n\")\n",
    "  cat(\"- u is an n×1 vector of errors\\n\")\n",
    "  cat(\"\\n\")\n",
    "  \n",
    "  cat(\"Step 1: Full regression\\n\")\n",
    "  cat(\"The full regression in matrix form is:\\n\")\n",
    "  cat(\"y = [X₁ X₂][β₁; β₂] + u = Xβ + u\\n\")\n",
    "  cat(\"\\n\")\n",
    "  cat(\"The OLS estimator is:\\n\")\n",
    "  cat(\"β̂ = (X'X)⁻¹X'y\\n\")\n",
    "  cat(\"\\n\")\n",
    "  cat(\"Partitioning X'X and X'y:\\n\")\n",
    "  cat(\"X'X = [X₁'X₁  X₁'X₂]\\n\")\n",
    "  cat(\"      [X₂'X₁  X₂'X₂]\\n\")\n",
    "  cat(\"\\n\")\n",
    "  cat(\"X'y = [X₁'y]\\n\")\n",
    "  cat(\"      [X₂'y]\\n\")\n",
    "  cat(\"\\n\")\n",
    "  \n",
    "  cat(\"Step 2: Using the partitioned inverse formula\\n\")\n",
    "  cat(\"For a partitioned matrix [A B; C D], if D is invertible:\\n\")\n",
    "  cat(\"The (1,1) block of the inverse is (A - BD⁻¹C)⁻¹\\n\")\n",
    "  cat(\"\\n\")\n",
    "  cat(\"Applying this to our case:\\n\")\n",
    "  cat(\"β̂₁ = [(X₁'X₁ - X₁'X₂(X₂'X₂)⁻¹X₂'X₁)]⁻¹[X₁'y - X₁'X₂(X₂'X₂)⁻¹X₂'y]\\n\")\n",
    "  cat(\"\\n\")\n",
    "  \n",
    "  cat(\"Step 3: Factoring out the projection matrix\\n\")\n",
    "  cat(\"Let M_{X₂} = I - X₂(X₂'X₂)⁻¹X₂' (the annihilator matrix)\\n\")\n",
    "  cat(\"Note that M_{X₂} is idempotent: M_{X₂}M_{X₂} = M_{X₂}\\n\")\n",
    "  cat(\"And symmetric: M_{X₂}' = M_{X₂}\\n\")\n",
    "  cat(\"\\n\")\n",
    "  cat(\"Then:\\n\")\n",
    "  cat(\"X₁'X₁ - X₁'X₂(X₂'X₂)⁻¹X₂'X₁ = X₁'[I - X₂(X₂'X₂)⁻¹X₂']X₁ = X₁'M_{X₂}X₁\\n\")\n",
    "  cat(\"X₁'y - X₁'X₂(X₂'X₂)⁻¹X₂'y = X₁'[I - X₂(X₂'X₂)⁻¹X₂']y = X₁'M_{X₂}y\\n\")\n",
    "  cat(\"\\n\")\n",
    "  \n",
    "  cat(\"Step 4: Final form\\n\")\n",
    "  cat(\"Therefore:\\n\")\n",
    "  cat(\"β̂₁ = (X₁'M_{X₂}X₁)⁻¹X₁'M_{X₂}y\\n\")\n",
    "  cat(\"\\n\")\n",
    "  cat(\"Let X̃₁ = M_{X₂}X₁ and ỹ = M_{X₂}y\\n\")\n",
    "  cat(\"Then: β̂₁ = (X̃₁'X̃₁)⁻¹X̃₁'ỹ\\n\")\n",
    "  cat(\"\\n\")\n",
    "  cat(\"This shows that β̂₁ from the full regression equals the OLS coefficient\\n\")\n",
    "  cat(\"from regressing the residuals ỹ on the residuals X̃₁.\\n\")\n",
    "  cat(\"\\n\")\n",
    "  cat(\"Q.E.D.\\n\")\n",
    "  cat(\"\\n\")\n",
    "}\n",
    "\n",
    "# Display the mathematical proof\n",
    "fwl_theorem_proof()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Verification\n",
    "\n",
    "Now let's verify the FWL theorem numerically using simulated data. We'll generate data with known parameters and compare the results from:\n",
    "1. Full regression: y ~ [X₁ X₂]\n",
    "2. FWL two-step procedure: residuals of y on residuals of X₁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "numerical_verification <- function() {\n",
    "  #' Numerical verification of the FWL theorem using simulated data.\n",
    "  \n",
    "  cat(\"=== NUMERICAL VERIFICATION ===\\n\\n\")\n",
    "  \n",
    "  # Set random seed for reproducibility\n",
    "  set.seed(42)\n",
    "  \n",
    "  # Generate data\n",
    "  n <- 1000  # Sample size\n",
    "  k1 <- 2    # Number of variables of interest\n",
    "  k2 <- 3    # Number of control variables\n",
    "  \n",
    "  # Generate X1, X2, and error term\n",
    "  X1 <- matrix(rnorm(n * k1), nrow = n, ncol = k1)\n",
    "  X2 <- matrix(rnorm(n * k2), nrow = n, ncol = k2)\n",
    "  u <- matrix(rnorm(n), nrow = n, ncol = 1)\n",
    "  \n",
    "  # True parameters\n",
    "  beta1_true <- matrix(c(1.5, 2.0), nrow = k1, ncol = 1)\n",
    "  beta2_true <- matrix(c(0.5, -1.0, 0.8), nrow = k2, ncol = 1)\n",
    "  \n",
    "  # Generate y\n",
    "  y <- X1 %*% beta1_true + X2 %*% beta2_true + u\n",
    "  \n",
    "  cat(sprintf(\"Sample size: %d\\n\", n))\n",
    "  cat(sprintf(\"X1 dimensions: (%d, %d) (variables of interest)\\n\", nrow(X1), ncol(X1)))\n",
    "  cat(sprintf(\"X2 dimensions: (%d, %d) (control variables)\\n\", nrow(X2), ncol(X2)))\n",
    "  cat(sprintf(\"True β₁: [%.1f, %.1f]\\n\", beta1_true[1], beta1_true[2]))\n",
    "  cat(sprintf(\"True β₂: [%.1f, %.1f, %.1f]\\n\", beta2_true[1], beta2_true[2], beta2_true[3]))\n",
    "  cat(\"\\n\")\n",
    "  \n",
    "  return(list(\n",
    "    X1 = X1, X2 = X2, y = y, n = n, k1 = k1, k2 = k2,\n",
    "    beta1_true = beta1_true, beta2_true = beta2_true\n",
    "  ))\n",
    "}\n",
    "\n",
    "# Generate the data\n",
    "data_setup <- numerical_verification()\n",
    "\n",
    "# Extract variables for easier access\n",
    "X1 <- data_setup$X1\n",
    "X2 <- data_setup$X2\n",
    "y <- data_setup$y\n",
    "n <- data_setup$n\n",
    "k1 <- data_setup$k1\n",
    "k2 <- data_setup$k2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Full Regression\n",
    "\n",
    "First, let's estimate the full regression model with all variables using matrix algebra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Method 1: Full regression\n",
    "X_full <- cbind(X1, X2)\n",
    "beta_full <- solve(t(X_full) %*% X_full) %*% (t(X_full) %*% y)\n",
    "beta1_full <- beta_full[1:k1, , drop = FALSE]\n",
    "\n",
    "cat(\"Method 1: Full regression\\n\")\n",
    "cat(sprintf(\"β̂₁ from full regression: [%.6f, %.6f]\\n\", beta1_full[1], beta1_full[2]))\n",
    "cat(\"\\n\")\n",
    "\n",
    "# Display the full coefficient vector\n",
    "cat(\"All coefficients from full regression:\\n\")\n",
    "for(i in 1:length(beta_full)) {\n",
    "  var_name <- if(i <= k1) paste0(\"β₁[\", i, \"]\") else paste0(\"β₂[\", i-k1, \"]\")\n",
    "  cat(sprintf(\"%s: %.6f\\n\", var_name, beta_full[i]))\n",
    "}\n",
    "cat(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: FWL Two-Step Procedure\n",
    "\n",
    "Now let's implement the FWL two-step procedure:\n",
    "1. Residualize y and X₁ with respect to X₂\n",
    "2. Regress the residualized y on the residualized X₁"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Method 2: FWL two-step procedure\n",
    "\n",
    "# Step 1: Regress y on X2 and get residuals\n",
    "P_X2 <- X2 %*% solve(t(X2) %*% X2) %*% t(X2)\n",
    "M_X2 <- diag(n) - P_X2\n",
    "y_tilde <- M_X2 %*% y\n",
    "\n",
    "# Step 2: Regress X1 on X2 and get residuals\n",
    "X1_tilde <- M_X2 %*% X1\n",
    "\n",
    "# Step 3: Regress y_tilde on X1_tilde\n",
    "beta1_fwl <- solve(t(X1_tilde) %*% X1_tilde) %*% (t(X1_tilde) %*% y_tilde)\n",
    "\n",
    "cat(\"Method 2: FWL two-step procedure\\n\")\n",
    "cat(\"Step 1: Residualize y on X₂\\n\")\n",
    "cat(\"Step 2: Residualize X₁ on X₂\\n\")\n",
    "cat(\"Step 3: Regress residuals\\n\")\n",
    "cat(sprintf(\"β̂₁ from FWL method: [%.6f, %.6f]\\n\", beta1_fwl[1], beta1_fwl[2]))\n",
    "cat(\"\\n\")\n",
    "\n",
    "# Show some properties of the projection matrices\n",
    "cat(\"Properties of projection matrices:\\n\")\n",
    "cat(sprintf(\"Rank of P_X2: %d (should equal k2 = %d)\\n\", qr(P_X2)$rank, k2))\n",
    "cat(sprintf(\"Rank of M_X2: %d (should equal n - k2 = %d)\\n\", qr(M_X2)$rank, n - k2))\n",
    "cat(sprintf(\"Trace of P_X2: %.0f (should equal k2 = %d)\\n\", sum(diag(P_X2)), k2))\n",
    "cat(sprintf(\"Trace of M_X2: %.0f (should equal n - k2 = %d)\\n\", sum(diag(M_X2)), n - k2))\n",
    "cat(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison and Verification\n",
    "\n",
    "Let's check if both methods produce identical results (within numerical precision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Check if they are equal (within numerical precision)\n",
    "difference <- abs(beta1_full - beta1_fwl)\n",
    "max_diff <- max(difference)\n",
    "\n",
    "cat(\"Verification:\\n\")\n",
    "cat(sprintf(\"Maximum absolute difference: %.2e\\n\", max_diff))\n",
    "cat(sprintf(\"Are they equal (within 1e-10)? %s\\n\", max_diff < 1e-10))\n",
    "cat(\"\\n\")\n",
    "\n",
    "# Show element-wise differences\n",
    "cat(\"Element-wise differences:\\n\")\n",
    "for(i in 1:k1) {\n",
    "  cat(sprintf(\"β₁[%d]: Full = %.8f, FWL = %.8f, Diff = %.2e\\n\", \n",
    "              i, beta1_full[i], beta1_fwl[i], difference[i]))\n",
    "}\n",
    "cat(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Verification using lm()\n",
    "\n",
    "Let's also verify using R's built-in `lm()` function to ensure our manual implementation is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Alternative verification using lm()\n",
    "cat(\"Alternative verification using lm():\\n\")\n",
    "\n",
    "# Create data frame for lm()\n",
    "df_full <- data.frame(y = as.vector(y), X_full)\n",
    "colnames(df_full) <- c(\"y\", paste0(\"X1_\", 1:k1), paste0(\"X2_\", 1:k2))\n",
    "\n",
    "# Full regression with lm()\n",
    "reg_full <- lm(y ~ . - 1, data = df_full)  # -1 removes intercept\n",
    "beta1_lm_full <- coef(reg_full)[1:k1]\n",
    "\n",
    "# Display full regression summary\n",
    "cat(\"\\nFull regression summary using lm():\\n\")\n",
    "print(summary(reg_full))\n",
    "\n",
    "# FWL with lm()\n",
    "# Step 1: Get residuals y_tilde\n",
    "df_x2 <- data.frame(X2)\n",
    "colnames(df_x2) <- paste0(\"X2_\", 1:k2)\n",
    "df_y_x2 <- data.frame(y = as.vector(y), df_x2)\n",
    "\n",
    "reg_y_on_x2 <- lm(y ~ . - 1, data = df_y_x2)\n",
    "y_tilde_lm <- residuals(reg_y_on_x2)\n",
    "\n",
    "# Step 2: Get residuals X1_tilde\n",
    "X1_tilde_lm <- matrix(0, nrow = n, ncol = k1)\n",
    "for (i in 1:k1) {\n",
    "  df_x1i_x2 <- data.frame(x1i = X1[, i], df_x2)\n",
    "  reg_x1i_on_x2 <- lm(x1i ~ . - 1, data = df_x1i_x2)\n",
    "  X1_tilde_lm[, i] <- residuals(reg_x1i_on_x2)\n",
    "}\n",
    "\n",
    "# Step 3: Final regression\n",
    "df_fwl <- data.frame(y_tilde = y_tilde_lm, X1_tilde_lm)\n",
    "colnames(df_fwl) <- c(\"y_tilde\", paste0(\"X1_tilde_\", 1:k1))\n",
    "\n",
    "reg_fwl <- lm(y_tilde ~ . - 1, data = df_fwl)\n",
    "beta1_lm_fwl <- coef(reg_fwl)\n",
    "\n",
    "cat(sprintf(\"\\nβ̂₁ from lm() full regression: [%.6f, %.6f]\\n\", beta1_lm_full[1], beta1_lm_full[2]))\n",
    "cat(sprintf(\"β̂₁ from lm() FWL method: [%.6f, %.6f]\\n\", beta1_lm_fwl[1], beta1_lm_fwl[2]))\n",
    "\n",
    "diff_lm <- abs(beta1_lm_full - beta1_lm_fwl)\n",
    "max_diff_lm <- max(diff_lm)\n",
    "cat(sprintf(\"Maximum absolute difference (lm): %.2e\\n\", max_diff_lm))\n",
    "cat(sprintf(\"Are they equal (within 1e-10)? %s\\n\", max_diff_lm < 1e-10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Results\n",
    "\n",
    "Let's create a comprehensive summary table of all our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create results summary\n",
    "results_summary <- data.frame(\n",
    "  Method = c(\"True Values\", \"Full Regression (Matrix)\", \"FWL Method (Matrix)\", \n",
    "             \"Full Regression (lm)\", \"FWL Method (lm)\"),\n",
    "  Beta1_1 = c(data_setup$beta1_true[1], beta1_full[1], beta1_fwl[1], \n",
    "               beta1_lm_full[1], beta1_lm_fwl[1]),\n",
    "  Beta1_2 = c(data_setup$beta1_true[2], beta1_full[2], beta1_fwl[2], \n",
    "               beta1_lm_full[2], beta1_lm_fwl[2])\n",
    ")\n",
    "\n",
    "cat(\"\\n=== RESULTS SUMMARY ===\\n\")\n",
    "print(results_summary, row.names = FALSE, digits = 6)\n",
    "\n",
    "cat(sprintf(\"\\nMaximum difference between methods: %.2e\\n\", max(max_diff, max_diff_lm)))\n",
    "cat(\"\\n✅ FWL Theorem verification SUCCESSFUL!\\n\")\n",
    "cat(\"The full regression and FWL two-step procedure produce identical results.\\n\")\n",
    "\n",
    "# Calculate R-squared for the full model\n",
    "y_pred_full <- X_full %*% beta_full\n",
    "sst <- sum((y - mean(y))^2)\n",
    "sse <- sum((y - y_pred_full)^2)\n",
    "r_squared <- 1 - sse/sst\n",
    "\n",
    "cat(sprintf(\"\\nModel fit statistics:\\n\"))\n",
    "cat(sprintf(\"R-squared: %.4f\\n\", r_squared))\n",
    "cat(sprintf(\"Residual sum of squares: %.2f\\n\", sse))\n",
    "cat(sprintf(\"Total sum of squares: %.2f\\n\", sst))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "Let's create some plots to visualize the relationship between the original and residualized variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create visualizations\n",
    "par(mfrow = c(2, 2), mar = c(4, 4, 3, 1))\n",
    "\n",
    "# Plot 1: Original y vs X1[,1]\n",
    "plot(X1[,1], y, xlab = \"X1[,1]\", ylab = \"y\", \n",
    "     main = \"Original Data: y vs X1[,1]\", \n",
    "     pch = 16, alpha = 0.6, col = \"blue\")\n",
    "abline(lm(y ~ X1[,1]), col = \"red\", lwd = 2)\n",
    "\n",
    "# Plot 2: Residualized y vs residualized X1[,1]\n",
    "plot(X1_tilde[,1], y_tilde, xlab = \"X1_tilde[,1]\", ylab = \"y_tilde\", \n",
    "     main = \"Residualized Data: y_tilde vs X1_tilde[,1]\", \n",
    "     pch = 16, alpha = 0.6, col = \"green\")\n",
    "abline(lm(y_tilde ~ X1_tilde[,1] - 1), col = \"red\", lwd = 2)\n",
    "\n",
    "# Plot 3: Original y vs X1[,2]\n",
    "plot(X1[,2], y, xlab = \"X1[,2]\", ylab = \"y\", \n",
    "     main = \"Original Data: y vs X1[,2]\", \n",
    "     pch = 16, alpha = 0.6, col = \"blue\")\n",
    "abline(lm(y ~ X1[,2]), col = \"red\", lwd = 2)\n",
    "\n",
    "# Plot 4: Residualized y vs residualized X1[,2]\n",
    "plot(X1_tilde[,2], y_tilde, xlab = \"X1_tilde[,2]\", ylab = \"y_tilde\", \n",
    "     main = \"Residualized Data: y_tilde vs X1_tilde[,2]\", \n",
    "     pch = 16, alpha = 0.6, col = \"green\")\n",
    "abline(lm(y_tilde ~ X1_tilde[,2] - 1), col = \"red\", lwd = 2)\n",
    "\n",
    "# Reset plotting parameters\n",
    "par(mfrow = c(1, 1))\n",
    "\n",
    "cat(\"\\nPlots show the relationship between original and residualized variables.\\n\")\n",
    "cat(\"The slope in the residualized plots corresponds to the FWL coefficients.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "We have successfully:\n",
    "\n",
    "1. **Provided a complete mathematical proof** of the Frisch-Waugh-Lovell theorem using partitioned matrix algebra\n",
    "2. **Numerically verified** the theorem using simulated data with both manual matrix operations and R's `lm()` function\n",
    "3. **Demonstrated** that both the full regression and the FWL two-step procedure produce identical estimates (within machine precision)\n",
    "4. **Visualized** the relationship between original and residualized variables\n",
    "\n",
    "The FWL theorem is a powerful tool in econometrics that allows us to:\n",
    "- Isolate the effect of specific variables by \"partialling out\" control variables\n",
    "- Understand the mechanics of multiple regression\n",
    "- Implement efficient computational methods for large datasets\n",
    "- Gain intuition about what multiple regression coefficients actually measure\n",
    "\n",
    "### Key Insights:\n",
    "- The projection matrix M_{X₂} removes the linear association with control variables\n",
    "- The residualized variables contain only the variation orthogonal to the controls\n",
    "- The FWL coefficient captures the relationship between y and X₁ after \"controlling for\" X₂\n",
    "- This provides the theoretical foundation for interpreting multiple regression coefficients\n",
    "\n",
    "**This completes Part 1 of Assignment 1 in R.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}