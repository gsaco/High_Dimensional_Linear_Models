{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# High-Dimensional Linear Models: Overfitting Simulation (R)\n",
    "\n",
    "This notebook demonstrates the overfitting phenomenon in high-dimensional linear models using R.\n",
    "We'll generate data with a nonlinear relationship and fit linear models with increasing numbers of polynomial features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load required libraries\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(tidyr)\n",
    "library(gridExtra)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "set.seed(42)\n",
    "cat(\"Libraries loaded successfully\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generating Process\n",
    "\n",
    "We use the specified data generating process:\n",
    "- f_X = exp(4 * X) - 1\n",
    "- y = f_X + ε, where ε ~ N(0, σ²)\n",
    "- n = 1000 observations\n",
    "- Intercept = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n <- 1000\n",
    "noise_std <- 0.5  # Standard deviation of the error term\n",
    "\n",
    "# Generate X from uniform distribution\n",
    "X <- runif(n, min = -0.5, max = 0.5)\n",
    "\n",
    "# Data generating process: f_X = exp(4 * X) - 1\n",
    "f_X <- exp(4 * X) - 1\n",
    "\n",
    "# Add noise to get Y\n",
    "epsilon <- rnorm(n, mean = 0, sd = noise_std)\n",
    "Y <- f_X + epsilon\n",
    "\n",
    "cat(\"Generated\", n, \"observations\\n\")\n",
    "cat(\"X range: [\", min(X), \",\", max(X), \"]\\n\")\n",
    "cat(\"Y range: [\", min(Y), \",\", max(Y), \"]\\n\")\n",
    "cat(\"True function range: [\", min(f_X), \",\", max(f_X), \"]\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of the True Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data frame for plotting\n",
    "data_df <- data.frame(X = X, Y = Y, f_X = f_X)\n",
    "\n",
    "# Plot the true relationship\n",
    "p1 <- ggplot(data_df, aes(x = X)) +\n",
    "  geom_point(aes(y = Y), alpha = 0.5, size = 1, color = \"blue\") +\n",
    "  geom_line(aes(y = f_X), color = \"red\", size = 1.5) +\n",
    "  labs(x = \"X\", y = \"Y\", title = \"Data Generating Process\") +\n",
    "  theme_minimal() +\n",
    "  theme(plot.title = element_text(hjust = 0.5))\n",
    "\n",
    "print(p1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for Model Fitting and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create polynomial features\n",
    "create_polynomial_features <- function(x, degree) {\n",
    "  n <- length(x)\n",
    "  X_poly <- matrix(0, nrow = n, ncol = degree)\n",
    "  \n",
    "  for (i in 1:degree) {\n",
    "    X_poly[, i] <- x^i\n",
    "  }\n",
    "  \n",
    "  return(X_poly)\n",
    "}\n",
    "\n",
    "# Function to calculate R-squared\n",
    "calculate_r2 <- function(y_true, y_pred) {\n",
    "  ss_res <- sum((y_true - y_pred)^2)\n",
    "  ss_tot <- sum((y_true - mean(y_true))^2)\n",
    "  return(1 - ss_res / ss_tot)\n",
    "}\n",
    "\n",
    "# Function to calculate adjusted R-squared\n",
    "calculate_adjusted_r2 <- function(r2, n, p) {\n",
    "  if (n <= p + 1) {\n",
    "    return(NA)\n",
    "  }\n",
    "  return(1 - (1 - r2) * (n - 1) / (n - p - 1))\n",
    "}\n",
    "\n",
    "# Function to fit and evaluate models\n",
    "fit_and_evaluate <- function(X_train, y_train, X_test, y_test, n_features) {\n",
    "  tryCatch({\n",
    "    # Create polynomial features\n",
    "    X_train_poly <- create_polynomial_features(X_train, n_features)\n",
    "    X_test_poly <- create_polynomial_features(X_test, n_features)\n",
    "    \n",
    "    # Fit linear regression without intercept using lm\n",
    "    # Create data frame for lm function\n",
    "    train_df <- data.frame(y = y_train, X_train_poly)\n",
    "    colnames(train_df) <- c(\"y\", paste0(\"X\", 1:n_features))\n",
    "    \n",
    "    # Fit model without intercept\n",
    "    formula_str <- paste(\"y ~\", paste(paste0(\"X\", 1:n_features), collapse = \" + \"), \"- 1\")\n",
    "    model <- lm(as.formula(formula_str), data = train_df)\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred <- predict(model)\n",
    "    \n",
    "    # For test predictions, create test data frame\n",
    "    test_df <- data.frame(X_test_poly)\n",
    "    colnames(test_df) <- paste0(\"X\", 1:n_features)\n",
    "    y_test_pred <- predict(model, newdata = test_df)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    r2_train <- calculate_r2(y_train, y_train_pred)\n",
    "    r2_test <- calculate_r2(y_test, y_test_pred)\n",
    "    adj_r2 <- calculate_adjusted_r2(r2_train, length(y_train), n_features)\n",
    "    \n",
    "    return(list(\n",
    "      r2 = r2_train,\n",
    "      adj_r2 = adj_r2,\n",
    "      r2_oos = r2_test,\n",
    "      n_params = n_features,\n",
    "      success = TRUE\n",
    "    ))\n",
    "  }, error = function(e) {\n",
    "    return(list(\n",
    "      r2 = NA,\n",
    "      adj_r2 = NA,\n",
    "      r2_oos = NA,\n",
    "      n_params = n_features,\n",
    "      success = FALSE,\n",
    "      error = as.character(e)\n",
    "    ))\n",
    "  })\n",
    "}\n",
    "\n",
    "cat(\"Functions defined successfully\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Simulation Loop\n",
    "\n",
    "We'll test models with different numbers of polynomial features: 1, 2, 5, 10, 20, 50, 100, 200, 500, 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train (75%) and test (25%)\n",
    "train_size <- floor(0.75 * n)\n",
    "indices <- sample(1:n, n, replace = FALSE)\n",
    "train_idx <- indices[1:train_size]\n",
    "test_idx <- indices[(train_size + 1):n]\n",
    "\n",
    "X_train <- X[train_idx]\n",
    "y_train <- Y[train_idx]\n",
    "X_test <- X[test_idx]\n",
    "y_test <- Y[test_idx]\n",
    "\n",
    "cat(\"Training set size:\", length(X_train), \"\\n\")\n",
    "cat(\"Test set size:\", length(X_test), \"\\n\")\n",
    "\n",
    "# Number of features to test\n",
    "feature_counts <- c(1, 2, 5, 10, 20, 50, 100, 200, 500, 1000)\n",
    "\n",
    "# Storage for results\n",
    "results <- data.frame(\n",
    "  n_features = integer(),\n",
    "  r2 = numeric(),\n",
    "  adj_r2 = numeric(),\n",
    "  r2_oos = numeric(),\n",
    "  n_params = integer(),\n",
    "  stringsAsFactors = FALSE\n",
    ")\n",
    "\n",
    "cat(\"\\nRunning simulation...\\n\")\n",
    "cat(\"Features | R² (train) | Adj R² | R² (test) | Parameters\\n\")\n",
    "cat(strrep(\"-\", 60), \"\\n\")\n",
    "\n",
    "for (n_features in feature_counts) {\n",
    "  # Skip if we don't have enough training samples\n",
    "  if (n_features >= length(X_train)) {\n",
    "    cat(sprintf(\"%8d | Skipped (insufficient training data)\\n\", n_features))\n",
    "    next\n",
    "  }\n",
    "  \n",
    "  metrics <- fit_and_evaluate(X_train, y_train, X_test, y_test, n_features)\n",
    "  \n",
    "  if (metrics$success) {\n",
    "    results <- rbind(results, data.frame(\n",
    "      n_features = n_features,\n",
    "      r2 = metrics$r2,\n",
    "      adj_r2 = metrics$adj_r2,\n",
    "      r2_oos = metrics$r2_oos,\n",
    "      n_params = metrics$n_params\n",
    "    ))\n",
    "    \n",
    "    cat(sprintf(\"%8d | %9.4f | %6.4f | %8.4f | %9d\\n\", \n",
    "               n_features, metrics$r2, metrics$adj_r2, metrics$r2_oos, metrics$n_params))\n",
    "  } else {\n",
    "    error_msg <- substr(metrics$error, 1, 30)\n",
    "    cat(sprintf(\"%8d | Error: %s...\\n\", n_features, error_msg))\n",
    "  }\n",
    "}\n",
    "\n",
    "cat(\"\\nCompleted simulation with\", nrow(results), \"successful models\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Visualization\n",
    "\n",
    "We create three separate plots showing how the different R-squared metrics change with the number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the three plots\n",
    "# Plot 1: R-squared (training)\n",
    "p1 <- ggplot(results, aes(x = n_features, y = r2)) +\n",
    "  geom_line(color = \"blue\", size = 1) +\n",
    "  geom_point(color = \"blue\", size = 2) +\n",
    "  scale_x_log10() +\n",
    "  ylim(0, 1) +\n",
    "  labs(x = \"Number of Features\", y = \"R-squared (Training)\",\n",
    "       title = \"Training R-squared vs Number of Features\") +\n",
    "  theme_minimal() +\n",
    "  theme(plot.title = element_text(hjust = 0.5))\n",
    "\n",
    "# Plot 2: Adjusted R-squared (filter out NA values)\n",
    "valid_adj <- results[!is.na(results$adj_r2), ]\n",
    "p2 <- ggplot(valid_adj, aes(x = n_features, y = adj_r2)) +\n",
    "  geom_line(color = \"green\", size = 1) +\n",
    "  geom_point(color = \"green\", size = 2) +\n",
    "  scale_x_log10() +\n",
    "  labs(x = \"Number of Features\", y = \"Adjusted R-squared\",\n",
    "       title = \"Adjusted R-squared vs Number of Features\") +\n",
    "  theme_minimal() +\n",
    "  theme(plot.title = element_text(hjust = 0.5))\n",
    "\n",
    "# Plot 3: Out-of-sample R-squared\n",
    "p3 <- ggplot(results, aes(x = n_features, y = r2_oos)) +\n",
    "  geom_line(color = \"red\", size = 1) +\n",
    "  geom_point(color = \"red\", size = 2) +\n",
    "  scale_x_log10() +\n",
    "  labs(x = \"Number of Features\", y = \"Out-of-sample R-squared\",\n",
    "       title = \"Out-of-sample R-squared vs Number of Features\") +\n",
    "  theme_minimal() +\n",
    "  theme(plot.title = element_text(hjust = 0.5))\n",
    "\n",
    "# Combine plots\n",
    "grid.arrange(p1, p2, p3, ncol = 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Analysis\n",
    "\n",
    "Let's examine the results and discuss the overfitting phenomenon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display summary statistics\n",
    "cat(\"Summary of Results:\\n\")\n",
    "cat(strrep(\"=\", 80), \"\\n\")\n",
    "print(results)\n",
    "\n",
    "# Find optimal number of features based on out-of-sample R²\n",
    "best_idx <- which.max(results$r2_oos)\n",
    "best_n_features <- results$n_features[best_idx]\n",
    "best_oos_r2 <- results$r2_oos[best_idx]\n",
    "\n",
    "cat(\"\\nOptimal number of features (based on out-of-sample R²):\", best_n_features, \"\\n\")\n",
    "cat(\"Best out-of-sample R²:\", round(best_oos_r2, 4), \"\\n\")\n",
    "\n",
    "# Calculate the difference between training and test R² to show overfitting\n",
    "results$overfitting <- results$r2 - results$r2_oos\n",
    "cat(\"\\nOverfitting Analysis (Training R² - Test R²):\\n\")\n",
    "overfitting_df <- results[, c(\"n_features\", \"overfitting\")]\n",
    "print(overfitting_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Visualization: Combined Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined plot showing all three metrics\n",
    "results_long <- results %>%\n",
    "  select(n_features, r2, adj_r2, r2_oos) %>%\n",
    "  pivot_longer(cols = c(r2, adj_r2, r2_oos), \n",
    "               names_to = \"metric\", \n",
    "               values_to = \"value\") %>%\n",
    "  filter(!is.na(value))\n",
    "\n",
    "# Rename metrics for better labels\n",
    "results_long$metric <- factor(results_long$metric, \n",
    "                             levels = c(\"r2\", \"adj_r2\", \"r2_oos\"),\n",
    "                             labels = c(\"Training R²\", \"Adjusted R²\", \"Out-of-sample R²\"))\n",
    "\n",
    "p_combined <- ggplot(results_long, aes(x = n_features, y = value, color = metric)) +\n",
    "  geom_line(size = 1) +\n",
    "  geom_point(size = 2) +\n",
    "  scale_x_log10() +\n",
    "  scale_color_manual(values = c(\"Training R²\" = \"blue\", \n",
    "                               \"Adjusted R²\" = \"green\", \n",
    "                               \"Out-of-sample R²\" = \"red\")) +\n",
    "  labs(x = \"Number of Features\", y = \"R-squared\",\n",
    "       title = \"Comparison of R-squared Metrics vs Number of Features\",\n",
    "       color = \"Metric\") +\n",
    "  theme_minimal() +\n",
    "  theme(plot.title = element_text(hjust = 0.5),\n",
    "        legend.position = \"bottom\")\n",
    "\n",
    "print(p_combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation and Conclusions\n",
    "\n",
    "### Overfitting Demonstration\n",
    "\n",
    "This simulation clearly demonstrates the overfitting phenomenon in high-dimensional linear models:\n",
    "\n",
    "1. **Training R-squared** monotonically increases as we add more polynomial features. This makes sense because with more parameters, the model can fit the training data more closely.\n",
    "\n",
    "2. **Adjusted R-squared** initially increases but then starts to decrease as the penalty for additional parameters outweighs the improvement in fit. This metric tries to balance model fit with model complexity.\n",
    "\n",
    "3. **Out-of-sample R-squared** typically increases initially as we capture more of the true nonlinear relationship, but then decreases as the model becomes too complex and starts fitting noise rather than signal.\n",
    "\n",
    "### Key Insights:\n",
    "\n",
    "- **Bias-Variance Tradeoff**: Simple models (few features) have high bias but low variance. Complex models (many features) have low bias but high variance.\n",
    "- **Optimal Complexity**: There's an optimal number of features that maximizes out-of-sample performance.\n",
    "- **Generalization**: Models that perform well on training data don't necessarily generalize well to new data.\n",
    "\n",
    "### R-Specific Observations:\n",
    "\n",
    "- R's built-in `lm()` function makes linear regression straightforward\n",
    "- The `ggplot2` package provides excellent visualization capabilities\n",
    "- Data manipulation with `dplyr` and `tidyr` makes data processing clean and readable\n",
    "- R's statistical functions make it easy to calculate various metrics\n",
    "\n",
    "### Practical Implications:\n",
    "\n",
    "- Always use cross-validation or hold-out samples to evaluate model performance\n",
    "- Consider regularization techniques (Ridge, Lasso) for high-dimensional problems\n",
    "- Be cautious of models with very high training accuracy but poor test performance\n",
    "- The true data generating process is nonlinear (exponential), but we're using polynomial approximations\n",
    "- Adjusted R-squared provides a better measure than regular R-squared when comparing models with different numbers of parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}